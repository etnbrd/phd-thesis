Automatically generated by Mendeley Desktop 1.16-dev1
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Salmito2014,
author = {Salmito, Tiago and de Moura, Ana L{\'{u}}cia and Rodriguez, Noemi},
doi = {10.1007/s11227-014-1110-4},
file = {:home/etn/Documents/PhD/Biblio/Salmito, de Moura, Rodriguez - 2014 - A stepwise approach to developing staged applications.pdf:pdf},
issn = {0920-8542},
journal = {The Journal of Supercomputing},
month = {jan},
title = {{A stepwise approach to developing staged applications}},
url = {http://link.springer.com/10.1007/s11227-014-1110-4},
year = {2014}
}
@inproceedings{Madsen2015,
address = {New York, New York, USA},
author = {Madsen, Kasper Grud Skat and Zhou, Yongluan},
booktitle = {Proceedings of the 24th ACM International on Conference on Information and Knowledge Management - CIKM '15},
doi = {10.1145/2806416.2806449},
file = {:home/etn/Documents/PhD/Biblio/Madsen, Zhou - 2015 - Dynamic Resource Management In a Massively Parallel Stream Processing Engine.pdf:pdf},
isbn = {9781450337946},
keywords = {elasticity,fault-tolerance,resource management},
month = {oct},
pages = {13--22},
publisher = {ACM Press},
title = {{Dynamic Resource Management In a Massively Parallel Stream Processing Engine}},
url = {http://dl.acm.org/citation.cfm?id=2806416.2806449},
year = {2015}
}
@article{Sun2015,
abstract = {In the big data era, big data stream computing, as a computing paradigm, is gaining traction for real-time and online data computing applications, and is specially designed to solve the dilemma of real-time data stream computing by processing data online within real-time constraints. It is used to compute large amounts of data in the form of continuous data streams. Each computation is represented by a data stream graph, usually a directed graph. In this paper, the computing paradigm of big data stream computation in data stream graph is given, and some application scenarios and big data stream characteristics are presented. A series of challenges in designing a scalable big data stream computing system in big data environments are summarised by referring to some research results of big data stream computing system, which include stateless system architecture, elastically adaptive scheduling strategy and fine-grained fault tolerance strategy. All these challenges will greatly help us to understand big dat...},
author = {Sun, Dawei and Liu, Chunxiao and Ren, Dongfeng},
journal = {International Journal of Wireless and Mobile Computing},
keywords = {adaptive scheduling,big data stream computing,fine-grained fault tolerance,stateless system architecture,system design,task scheduling},
language = {en},
month = {oct},
publisher = {Inderscience Publishers (IEL)},
title = {{Prospects, challenges and latest developments in designing a scalable big data stream computing system}},
url = {http://www.inderscienceonline.com/doi/abs/10.1504/IJWMC.2015.072567},
year = {2015}
}
@article{Olston2008,
abstract = {There is a growing need for ad-hoc analysis of extremely large data sets, especially at internet companies where inno- vation critically depends on being able to analyze terabytes of data collected every day. Parallel database products, e.g., Teradata, offer a solution, but are usually prohibitively ex- pensive at this scale. Besides, many of the people who ana- lyze this data are entrenched procedural programmers, who find the declarative, SQL style to be unnatural. The success of the more procedural map-reduce programming model, and its associated scalable implementations on commodity hard- ware, is evidence of the above. However, the map-reduce paradigm is too low-level and rigid, and leads to a great deal of custom user code that is hard to maintain, and reuse. We describe a new language called Pig Latin that we have designed to fit in a sweet spot between the declarative style of SQL, and the low-level, procedural style of map-reduce. The accompanying system, Pig, is fully implemented, and compiles Pig Latin into physical plans that are executed over Hadoop, an open-source, map-reduce implementation. We give a few examples of how engineers at Yahoo! are using Pig to dramatically reduce the time required for the develop- ment and execution of their data analysis tasks, compared to using Hadoop directly. We also report on a novel debugging environment that comes integrated with Pig, that can lead to even higher productivity gains. Pig is an open-source, Apache-incubator project, and available for general use.},
address = {New York, New York, USA},
author = {Olston, Christopher and Reed, Benjamin and Srivastava, Utkarsh and Kumar, Ravi and Tomkins, Andrew},
doi = {10.1145/1376616.1376726},
file = {:home/etn/Documents/PhD/Biblio/Olston et al. - 2008 - Pig Latin A Not-So-Foreign Language for Data Processing.pdf:pdf},
isbn = {978-1-60558-102-6},
issn = {07308078},
journal = {Proceedings of the 2008 ACM SIGMOD international conference on Management of data - SIGMOD '08},
keywords = {dataflow language,pig latin},
month = {jun},
pages = {1099},
publisher = {ACM Press},
title = {{Pig Latin: A Not-So-Foreign Language for Data Processing}},
url = {http://dl.acm.org/citation.cfm?id=1376616.1376726},
year = {2008}
}
