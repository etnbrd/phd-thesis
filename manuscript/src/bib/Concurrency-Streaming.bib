Automatically generated by Mendeley Desktop 1.16-dev2
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Buddhika2016,
author = {Buddhika, T and Pallickara, S},
file = {:home/etn/Documents/PhD/Biblio/Buddhika, Pallickara - Unknown - NEPTUNE Real Time Stream Processing for Internet of Things and Sensing Environments.pdf:pdf},
journal = {granules.cs.colostate.edu},
title = {{NEPTUNE: Real Time Stream Processing for Internet of Things and Sensing Environments}},
url = {http://granules.cs.colostate.edu/papers/Neptune-IPDPS-2016.pdf}
}
@article{Zaharia2012,
abstract = {Many important "big data" applications need to process data arriving in real time. However, current programming models for distributed stream processing are relatively low-level, often leaving the user to worry about consistency of state across the system and fault recovery. Furthermore, the models that provide fault recovery do so in an expensive manner, requiring either hot replication or long recovery times. We propose a new programming model, discretized streams (D-Streams), that offers a high-level functional programming API, strong consistency, and efficient fault recovery. D-Streams support a new recovery mechanism that improves efficiency over the traditional replication and upstream backup solutions in streaming databases: parallel recovery of lost state across the cluster. We have prototyped D-Streams in an extension to the Spark cluster computing framework called Spark Streaming, which lets users seamlessly intermix streaming, batch and interactive queries.},
author = {Zaharia, Matei and Das, Tathagata and Li, Haoyuan and Shenker, Scott and Stoica, Ion},
file = {:home/etn/Documents/PhD/Biblio/Zaharia et al. - 2012 - Discretized streams an efficient and fault-tolerant model for stream processing on large clusters.pdf:pdf},
journal = {Proceedings of the 4th USENIX conference on Hot Topics in Cloud Ccomputing},
pages = {10--10},
title = {{Discretized streams: an efficient and fault-tolerant model for stream processing on large clusters}},
url = {https://www.usenix.org/system/files/conference/hotcloud12/hotcloud12-final28.pdf},
year = {2012}
}
@article{Qian2013,
author = {Qian, Z and He, Y and Su, C and Wu, Z and Zhu, H},
journal = {Proceedings of the 8th ACM European Conference on Computer Systems (EuroSys '13)},
title = {{Timestream: Reliable stream computation in the cloud}},
url = {http://dl.acm.org/citation.cfm?id=2465353},
year = {2013}
}
@article{Isard2007,
author = {Isard, M and Budiu, M and Yu, Y and Birrell, A and Fetterly, D},
journal = {ACM SIGOPS Operating  {\ldots}},
title = {{Dryad: distributed data-parallel programs from sequential building blocks}},
url = {http://dl.acm.org/citation.cfm?id=1273005},
year = {2007}
}
@article{Stonebraker2005,
author = {Stonebraker, M and {\c{C}}etintemel, U and Zdonik, S},
journal = {ACM SIGMOD Record},
title = {{The 8 requirements of real-time stream processing}},
url = {http://dl.acm.org/citation.cfm?id=1107504},
year = {2005}
}
@inproceedings{Giorgi2012,
abstract = {The TERAFLUX project is a Future and Emerging Technologies (FET) Large-Scale
Project funded by the European Union. TERAFLUX is at the forefront
of major research challenges such as programmability, manageable
architecture design, reliability of many-core or 1000+ core chips.
In the near future, new computing systems will consist of a huge
number of transistors - probably 1 Tera or 1000 billions by 2020:
we name such systems as "Teradevices". In this project, the aim is
to solve the three challenges at once by using the dataflow principles
wherever they are applicable or make sense in the general economy
of the system. An Instruction Set Extension (ISE) for the x86-64
is illustrated. This ISE supports the dataflow execution of threads.},
author = {Giorgi, Roberto},
booktitle = {Proceedings of the 9th conference on Computing Frontiers},
keywords = {dataflow},
organization = {ACM},
pages = {303--304},
title = {{TERAFLUX: exploiting dataflow parallelism in teradevices}},
url = {http://dl.acm.org/citation.cfm?id=2212959},
year = {2012}
}
@mastersthesis{Wong2012,
author = {Wong, Eric},
keywords = {alire,dataflow},
school = {Massachusetts Institute of Technology},
title = {{Optimizations in Stream Programming for Multimedia Applications}},
year = {2012}
}
@techreport{Soule2012a,
abstract = {Developers increasingly use stream processing languages to write applications that process large volumes of data with high throughput. Unfortunately, when choosing which stream processing language to use, they face a difficult choice. On the one hand, dynamically scheduled languages allow developers to write a wider range of applications, but cannot take advantage of many crucial optimizations. On the other hand, statically scheduled languages are extremely performant, but cannot express many important streaming applications. This paper presents the design of a hybrid scheduler for stream processing languages. The compiler partitions the streaming application into coarse-grained subgraphs sepa- rated by dynamic rate boundaries. It then applies static op- timizations to those subgraphs. We have implemented this scheduler as an extension to the StreamIt compiler, and eval- uated its performance against three scheduling techniques used by dynamic systems: OS thread, demand, and no-op. Our scheduler not only allows the previously static version of StreamIt to run dynamic rate applications, but it outper- forms the three dynamic alternatives. This demonstrates that our scheduler strikes the right balance between expressivity and performance for stream processing languages.},
author = {Soul{\'{e}}, Robert and Gordon, Michael I and Amarasinghe, Saman and Grimm, Robert and Hirzel, Martin},
institution = {New York University},
keywords = {dataflow},
number = {Technical Report TR2012-948},
title = {{Hitting the Sweet Spot for Streaming Languages: Dynamic Expressivity with Static Optimization}},
year = {2012}
}
@inproceedings{Wu2009,
author = {Wu, Nan and Wen, Mei and Wu, Wei and Ren, Ju and Su, Huayou and Xun, Changqing and Zhang, Chunyuan},
booktitle = {Proceedings of the 17th ACM international conference on Multimedia},
keywords = {alire,dataflow},
organization = {ACM},
pages = {371--380},
title = {{Streaming HD H. 264 encoder on programmable processors}},
url = {http://dl.acm.org/citation.cfm?id=1631324},
year = {2009}
}
@article{Yu2009,
author = {Yu, Yuan and Isard, Michael and Fetterly, Dennis and Budiu, Mihai and Erlingsson, Ulfar and Gunda, Pradeep Kumar and Currey, Jon and McSherry, Frank and Achan, Kannan and Poulain, Christophe},
journal = {Microsoft Research},
title = {{Some sample programs written in DryadLINQ}},
url = {http://research.microsoft.com/jump/66811},
year = {2009}
}
@article{Balazinska2008,
author = {Balazinska, M and Balakrishnan, H},
journal = {{\ldots}  on Database Systems ( {\ldots}},
title = {{Fault-tolerance in the Borealis distributed stream processing system}},
url = {http://dl.acm.org/citation.cfm?id=1331907},
year = {2008}
}
@article{Chen2000,
author = {Chen, J and DeWitt, DJ and Tian, F and Wang, Y},
journal = {ACM SIGMOD Record},
title = {{NiagaraCQ: A scalable continuous query system for internet databases}},
url = {http://dl.acm.org/citation.cfm?id=335432},
year = {2000}
}
@article{Aref2004,
author = {Aref, WG and Elmagarmid, AK},
journal = {{\ldots}  on Data  {\ldots}},
title = {{Nile: a query processing engine for data streams}},
url = {http://www-users.cs.umn.edu/{~}mokbel/papers/NileDemo.pdf},
year = {2004}
}
@article{Naughton2001,
author = {Naughton, JF and DeWitt, DJ and Maier, D},
journal = {IEEE Data Eng. {\ldots}},
title = {{The Niagara internet query system}},
url = {http://www.cs.cornell.edu/People/Jai/papers/niagaraoverview.pdf},
year = {2001}
}
@article{Yang,
author = {Yang, F and Qian, Z and Chen, X and Beschastnikh, I},
journal = {research.microsoft.com},
title = {{Sonora: A Platform for Continuous Mobile-Cloud Computing}},
url = {http://research.microsoft.com/pubs/161446/paper.pdf},
year = {2012}
}
@article{Murray2011,
author = {Murray, DG and Schwarzkopf, M},
file = {:home/etn/Documents/PhD/Biblio/Murray, Schwarzkopf - 2011 - CIEL a universal execution engine for distributed data-flow computing.pdf:pdf},
journal = {Proceedings of the {\ldots}},
title = {{CIEL: a universal execution engine for distributed data-flow computing}},
url = {http://static.usenix.org/event/nsdi11/tech/full{\_}papers/Murray.pdf},
year = {2011}
}
@article{Gedik2008,
author = {Gedik, B and Andrade, H and Wu, KL and Yu, PS and Doo, M},
journal = {Proceedings of the 2008  {\ldots}},
title = {{SPADE: the system s declarative stream processing engine}},
url = {http://dl.acm.org/citation.cfm?id=1376729},
year = {2008}
}
@article{Barga2006,
author = {Barga, RS and Goldstein, J and Ali, M and Hong, M},
journal = {arXiv preprint cs/0612115},
title = {{Consistent streaming through time: A vision for event stream processing}},
url = {http://arxiv.org/abs/cs/0612115},
year = {2006}
}
@inproceedings{Meijer2006,
address = {New York, New York, USA},
author = {Meijer, Erik and Beckman, Brian and Bierman, Gavin},
booktitle = {Proceedings of the 2006 ACM SIGMOD international conference on Management of data - SIGMOD '06},
doi = {10.1145/1142473.1142552},
isbn = {1595934340},
month = {jun},
pages = {706},
publisher = {ACM Press},
title = {{LINQ}},
url = {http://dl.acm.org/citation.cfm?id=1142473.1142552},
year = {2006}
}
@article{Krishnamurthy2003,
author = {Krishnamurthy, S and Chandrasekaran, S},
file = {:home/etn/Documents/PhD/Biblio/Krishnamurthy, Chandrasekaran - 2003 - TelegraphCQ An architectural status report.pdf:pdf},
journal = {IEEE Data Eng. {\ldots}},
title = {{TelegraphCQ: An architectural status report}},
url = {http://db.lcs.mit.edu/madden/html/deissue-b.pdf{\#}page=13},
year = {2003}
}
@article{Zaharia,
author = {Zaharia, M and Chowdhury, M and Das, T and Dave, A},
file = {:home/etn/Documents/PhD/Biblio/Zaharia et al. - 2010 - Fast and interactive analytics over Hadoop data with Spark.pdf:pdf},
journal = {usenix.org},
pages = {45--51},
title = {{Fast and interactive analytics over Hadoop data with Spark}},
url = {https://www.usenix.org/system/files/login/articles/zaharia.pdf},
year = {2010}
}
@article{Akidau2013,
author = {Akidau, T and Balikov, A},
journal = {Proceedings of the VLDB Endowment 6.11},
title = {{MillWheel: Fault-Tolerant Stream Processing at Internet Scale}},
url = {http://research.google.com/pubs/archive/41378.pdf},
year = {2013}
}
@article{Gautier1987,
author = {Gautier, T and Guernic, P Le and Besnard, L},
journal = {Functional programming languages  {\ldots}},
title = {{Signal: A declarative language for synchronous programming of real-time systems}},
url = {http://link.springer.com/chapter/10.1007/3-540-18317-5{\_}15},
year = {1987}
}
@article{He2010,
author = {He, B and Yang, M and Guo, Z and Chen, R and Su, B},
file = {:home/etn/Documents/PhD/Biblio/He et al. - 2010 - Comet batched stream processing for data intensive distributed computing.pdf:pdf},
journal = {{\ldots} on Cloud computing},
title = {{Comet: batched stream processing for data intensive distributed computing}},
url = {http://dl.acm.org/citation.cfm?id=1807139},
year = {2010}
}
@article{Logothetis2010,
abstract = {This work addresses the need for stateful dataflow programs that can rapidly sift through huge, evolving data sets. These data-intensive applications perform complex multi-step computations over successive generations of data inflows, such as weekly web crawls, daily image/video uploads, log files, and growing social networks. While programmers may simply re-run the entire dataflow when new data arrives, this is grossly inefficient, increasing result latency and squandering hardware resources and energy. Alternatively, programmers may use prior results to incrementally incorporate the changes. However, current large-scale data processing tools, such as Map-Reduce or Dryad, limit how programmers incorporate and use state in data-parallel programs. Straightforward approaches to incorporating state can result in custom, fragile code and disappointing performance. This work presents a generalized architecture for continuous bulk processing (CBP) that raises the level of abstraction for building incremental applications. At its core is a flexible, groupwise processing operator that takes state as an explicit input. Unifying stateful programming with a data-parallel operator affords several fundamental opportunities for minimizing the movement of data in the underlying processing system. As case studies, we show how one can use a small set of flexible dataflow primitives to perform web analytics and mine large-scale, evolving graphs in an incremental fashion. Experiments with our prototype using real-world data indicate significant data movement and running time reductions relative to current practice. For example, incrementally computing PageRank using CBP can reduce data movement by 46{\%} and cut running time in half.},
author = {Logothetis, Dionysios and Olston, Christopher and Reed, Benjamin and Webb, Kevin C. and Yocum, Ken},
doi = {10.1145/1807128.1807138},
file = {:home/etn/Documents/PhD/Biblio/Logothetis et al. - 2010 - Stateful bulk processing for incremental analytics.pdf:pdf},
isbn = {9781450300360},
journal = {International Conference on Management of Data},
keywords = {cloud computing,incremental,mapreduce,parallel data processing},
pages = {51--62},
title = {{Stateful bulk processing for incremental analytics}},
url = {http://dl.acm.org/citation.cfm?id=1807138 http://portal.acm.org/citation.cfm?id=1807128.1807138},
year = {2010}
}
@article{Peng2010,
author = {Peng, D and Dabek, F},
journal = {OSDI},
title = {{Large-scale Incremental Processing Using Distributed Transactions and Notifications.}},
url = {http://www.usenix.org/event/osdi10/tech/full{\_}papers/Peng.pdf},
year = {2010}
}
@article{McSherry,
abstract = {We report on the design and implementation of Naiad, a set of declarative$\backslash$ndata-parallel language extensions and an associated runtime supporting efficient$\backslash$nand composable incremental and iterative computation. This combination is$\backslash$nenabled by a new computational model we call differential dataflow, in which$\backslash$nincremental computation can be performed using a partial, rather than total,$\backslash$norder on time. $\backslash$n$\backslash$n Naiad extends standard batch data-parallel processing models like MapReduce,$\backslash$nHadoop, and Dryad/DryadLINQ, to support efficient incremental updates to the$\backslash$ninputs in the manner of a stream processing system, while at the same time$\backslash$nenabling arbitrarily nested fixed-point iteration. In this paper, we evaluate a$\backslash$nprototype of Naiad that uses shared memory on a single multi-core computer. We$\backslash$napply Naiad to various computations, including several graph algorithms, and$\backslash$nobserve good scaling properties and efficient incremental recomputation.},
author = {McSherry, F and Isaacs, R and Isard, M and Murray, DG},
file = {:home/etn/Documents/PhD/Biblio/McSherry et al. - 2012 - Composable Incremental and Iterative Data-Parallel Computation with Naiad.pdf:pdf},
journal = {Microsoft Research},
title = {{Composable Incremental and Iterative Data-Parallel Computation with Naiad}},
url = {http://202.114.89.42/resource/pdf/6992.pdf},
year = {2012}
}
@article{Condie2010,
author = {Condie, T and Conway, N and Alvaro, P},
journal = {NSDI},
title = {{MapReduce Online.}},
url = {http://static.usenix.org/events/nsdi10/tech/full{\_}papers/condie.pdf},
year = {2010}
}
@misc{Apache2011,
author = {Apache},
title = {{Apache Flume}},
url = {http://flume.apache.org/},
year = {2011}
}
@article{Amini2006,
author = {Amini, L and Andrade, H and Bhagwan, R},
file = {:home/etn/Documents/PhD/Biblio/Amini, Andrade, Bhagwan - 2006 - SPC A distributed, scalable platform for data mining.pdf:pdf},
journal = {{\ldots} on Data mining {\ldots}},
title = {{SPC: A distributed, scalable platform for data mining}},
url = {http://dl.acm.org/citation.cfm?id=1289615},
year = {2006}
}
@misc{Marz2011,
abstract = {Storm is a free and open source distributed realtime computation system. Storm makes it easy to reliably process unbounded streams of data, doing for realtime processing what Hadoop did for batch processing. Storm is simple, can be used with any programming language, and is a lot of fun to use!},
author = {Marz, Nathan and Xu, James and Jackson, Jason and Feng, Andy},
title = {{Storm}},
url = {http://storm-project.net/},
year = {2011}
}
@inproceedings{Neumeyer2010,
abstract = {S4 is a general-purpose, distributed, scalable, partially fault-tolerant, pluggable platform that allows programmers to easily develop applications for processing continuous unbounded streams of data. Keyed data events are routed with affinity to Processing Elements (PEs), which consume the events and do one or both of the following: (1) emit one or more events which may be consumed by other PEs, (2) publish results. The architecture resembles the Actors model, providing semantics of encapsulation and location transparency, thus allowing applications to be massively concurrent while exposing a simple programming interface to application developers. In this paper, we outline the S4 architecture in detail, describe various applications, including real-life deployments. Our design is primarily driven by large scale applications for data mining and machine learning in a production environment. We show that the S4 design is surprisingly flexible and lends itself to run in large clusters built with commodity hardware.},
author = {Neumeyer, Leonardo and Robbins, Bruce and Nair, Anish and Kesari, Anand},
booktitle = {Proceedings - IEEE International Conference on Data Mining, ICDM},
doi = {10.1109/ICDMW.2010.172},
file = {:home/etn/Documents/PhD/Biblio/Neumeyer et al. - 2010 - S4 Distributed stream computing platform.pdf:pdf},
isbn = {9780769542577},
issn = {15504786},
keywords = {Actors programming model,Complex event processing,Concurrent programming,Data processing,Distributed programming,Map-reduce,Middleware,Parallel programming,Real-time search,Software design,Stream computing},
pages = {170--177},
title = {{S4: Distributed stream computing platform}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5693297},
year = {2010}
}
@article{Abadi2005,
author = {Abadi, DJ and Ahmad, Y and Balazinska, M},
journal = {CIDR},
title = {{The Design of the Borealis Stream Processing Engine.}},
url = {http://www.cs.harvard.edu/{~}mdw/course/cs260r/papers/borealis-cidr05.pdf},
year = {2005}
}
@article{Arvind2003,
author = {Arvind, DP and Arasu, A and Babcock, B},
journal = {IEEE Data Engineering {\ldots}},
title = {{Stream: The stanford stream data manager}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.8.6180},
year = {2003}
}
@article{Chandrasekaran2003,
author = {Chandrasekaran, S and Cooper, O},
journal = {Proceedings of the {\ldots}},
title = {{TelegraphCQ: continuous dataflow processing}},
url = {http://dl.acm.org/citation.cfm?id=872857},
year = {2003}
}
@article{Balakrishnan2004,
author = {Balakrishnan, H and Balazinska, M},
journal = {The VLDB Journal},
title = {{Retrospective on aurora}},
url = {http://link.springer.com/article/10.1007/s00778-004-0133-5},
year = {2004}
}
@misc{TechnicalComittee2003,
author = {{Technical Comittee}},
booktitle = {Data Engineering},
number = {1},
title = {{Special Issue on Data Stream Processing}},
url = {http://people.cs.aau.dk/{~}tbp/BIT/moede10/A03MAR-CD.pdf{\#}page=5},
volume = {26},
year = {2003}
}
@article{Abadi2003,
author = {Abadi, D and Carney, D and Cetintemel, U},
journal = {Proceedings of the {\ldots}},
title = {{Aurora: a data stream management system}},
url = {http://dl.acm.org/citation.cfm?id=872855},
year = {2003}
}
@article{Abadi2003a,
author = {Abadi, DJ and Carney, D},
journal = {The VLDB Journal— {\ldots}},
title = {{Aurora: a new model and architecture for data stream management}},
url = {http://dl.acm.org/citation.cfm?id=950485},
year = {2003}
}
@article{Bhatotia2011,
abstract = {Many online data sets evolve over time as new entries are slowly added and existing entries are deleted or modified. Taking advantage of this, systems for incremental bulk data processing, such as Google's Percolator, can achieve efficient updates. To achieve this efficiency, however, these systems lose compatibility with the simple programming models offered by non-incremental systems, e.g., MapReduce, and more importantly, requires the programmer to implement application-specific dynamic algorithms, ultimately increasing algorithm and code complexity. In this paper, we describe the architecture, implementation, and evaluation of Incoop, a generic MapReduce framework for incremental computations. Incoop detects changes to the input and automatically updates the output by employing an efficient, fine-grained result reuse mechanism. To achieve efficiency without sacrificing transparency, we adopt recent advances in the area of programming languages to identify the shortcomings of task-level memoization approaches, and to address these shortcomings by using several novel techniques: a storage system, a contraction phase for Reduce tasks, and an affinity-based scheduling algorithm. We have implemented Incoop by extending the Hadoop framework, and evaluated it by considering several applications and case studies. Our results show significant performance improvements without changing a single line of application code.},
author = {Bhatotia, Pramod and Wieder, Alexander and Rodrigues, Rodrigo and Acar, Umut a and Pasquin, Rafael},
doi = {10.1145/2038916.2038923},
file = {:home/etn/Documents/PhD/Biblio/Bhatotia et al. - 2011 - Incoop MapReduce for incremental computations(2).pdf:pdf},
isbn = {9781450309769},
issn = {1450309763},
journal = {Proceedings of the 2nd ACM Symposium on Cloud Computing - SOCC '11},
keywords = {memoization,self-adjusting computation,stability},
pages = {1--14},
pmid = {11412367},
title = {{Incoop: MapReduce for incremental computations}},
url = {http://dl.acm.org/citation.cfm?id=2038923 http://dl.acm.org/citation.cfm?doid=2038916.2038923},
year = {2011}
}
@article{Consel2003,
author = {Consel, C and Hamdi, H and R{\'{e}}veill{\`{e}}re, L},
file = {:home/etn/Documents/PhD/Biblio/Consel, Hamdi, R{\'{e}}veill{\`{e}}re - 2003 - Spidle a DSL approach to specifying streaming applications.pdf:pdf},
journal = {Generative  {\ldots}},
title = {{Spidle: a DSL approach to specifying streaming applications}},
url = {http://link.springer.com/chapter/10.1007/978-3-540-39815-8{\_}1},
year = {2003}
}
@article{Jain2006,
author = {Jain, N and Amini, L and Andrade, H and King, R},
file = {:home/etn/Documents/PhD/Biblio/Jain et al. - 2006 - Design, implementation, and evaluation of the linear road benchmark on the stream processing core.pdf:pdf},
journal = {Proceedings of the {\ldots}},
title = {{Design, implementation, and evaluation of the linear road benchmark on the stream processing core}},
url = {http://dl.acm.org/citation.cfm?id=1142522},
year = {2006}
}
@article{Wu2007,
author = {Wu, KL and Hildrum, KW and Fan, W},
file = {:home/etn/Documents/PhD/Biblio/Wu, Hildrum, Fan - 2007 - Challenges and experience in prototyping a multi-modal stream analytic and monitoring application on System S.pdf:pdf},
journal = {Proceedings of the 33rd {\ldots}},
title = {{Challenges and experience in prototyping a multi-modal stream analytic and monitoring application on System S}},
url = {http://dl.acm.org/citation.cfm?id=1325986},
year = {2007}
}
@article{Gribble2001,
abstract = {The Ninja project seeks to enable the broad innovation of robust, scalable, distributed Internet services, and to permit the emerging class of extremely heterogeneous devices to seamlessly access these services. Our architecture consists of four basic elements: bases, which are powerful workstation cluster environments with a software platform that simplifies scalable service construction; units, which are the devices by which users access the services; active proxies, which are transformational elements that are used for unit- or service-specific adaptation; and paths, which are an abstraction through which units, services, and active proxies are composed.},
author = {Gribble, Steven D. and Welsh, Matt and {Von Behren}, Rob and Brewer, Eric a. and Culler, David and Borisov, N. and Czerwinski, S. and Gummadi, R. and Hill, J. and Joseph, A. and Katz, R. H. and Mao, Z. M. and Ross, S. and Zhao, B.},
doi = {10.1016/S1389-1286(00)00179-1},
file = {:home/etn/Documents/PhD/Biblio/Gribble, Welsh, Behren - 2001 - The Ninja architecture for robust Internet-scale systems and services.pdf:pdf},
isbn = {1389-1286},
issn = {13891286},
journal = {Computer Networks},
keywords = {distributed systems,ninja architecture,pervasive computing,scalable services,thin clients},
number = {4},
pages = {473--497},
title = {{Ninja architecture for robust Internet-scale systems and services}},
url = {http://www.sciencedirect.com/science/article/pii/S1389128600001791},
volume = {35},
year = {2001}
}
@article{Salmito2014,
author = {Salmito, Tiago and de Moura, Ana L{\'{u}}cia and Rodriguez, Noemi},
doi = {10.1007/s11227-014-1110-4},
file = {:home/etn/Documents/PhD/Biblio/Salmito, de Moura, Rodriguez - 2014 - A stepwise approach to developing staged applications.pdf:pdf},
issn = {0920-8542},
journal = {The Journal of Supercomputing},
month = {jan},
title = {{A stepwise approach to developing staged applications}},
url = {http://link.springer.com/10.1007/s11227-014-1110-4},
year = {2014}
}
@article{Welsh2001,
author = {Welsh, M and Culler, D and Brewer, E},
file = {:home/etn/Documents/PhD/Biblio/Welsh, Culler, Brewer - 2001 - SEDA an architecture for well-conditioned, scalable internet services.pdf:pdf},
journal = {ACM SIGOPS Operating Systems Review},
title = {{SEDA: an architecture for well-conditioned, scalable internet services}},
url = {http://dl.acm.org/citation.cfm?id=502057},
year = {2001}
}
@article{Fernandez2013,
author = {Fernandez, R Castro},
file = {:home/etn/Documents/PhD/Biblio/Fernandez - 2013 - Integrating scale out and fault tolerance in stream processing using operator state management.pdf:pdf},
journal = {Proceedings of the  {\ldots}},
title = {{Integrating scale out and fault tolerance in stream processing using operator state management}},
url = {http://dl.acm.org/citation.cfm?id=2465282},
year = {2013}
}
@article{Migliavacca2010,
author = {Migliavacca, M and Eyers, D},
journal = {Middleware'10 Posters  {\ldots}},
title = {{SEEP: scalable and elastic event processing}},
url = {http://dl.acm.org/citation.cfm?id=1930032},
year = {2010}
}
@article{Golab2003,
author = {Golab, L and {\"{O}}zsu, MT},
file = {:home/etn/Documents/PhD/Biblio/Golab, {\"{O}}zsu - 2003 - Issues in data stream management.pdf:pdf},
journal = {ACM Sigmod Record},
title = {{Issues in data stream management}},
url = {http://dl.acm.org/citation.cfm?id=776986},
year = {2003}
}
@article{Fernandez2014a,
author = {Fernandez, Raul Castro and Migliavacca, Matteo and Kalyvianaki, Evangelia and Pietzuch, Peter},
file = {:home/etn/Documents/PhD/Biblio/Fernandez et al. - 2014 - Making state explicit for imperative big data processing.pdf:pdf},
journal = {USENIX ATC},
title = {{Making state explicit for imperative big data processing}},
url = {https://www.usenix.org/system/files/conference/atc14/atc14-paper-castro{\_}fernandez.pdf},
year = {2014}
}
@article{Power2010,
author = {Power, R and Li, J},
file = {:home/etn/Documents/PhD/Biblio/Power, Li - 2010 - Piccolo Building Fast, Distributed Programs with Partitioned Tables.pdf:pdf},
journal = {OSDI},
title = {{Piccolo: Building Fast, Distributed Programs with Partitioned Tables.}},
url = {http://static.usenix.org/event/osdi10/tech/full{\_}papers/Power.pdf},
year = {2010}
}
@article{Bartenstein2014,
author = {Bartenstein, Thomas W and Liu, Yu David},
doi = {10.1145/2660193.2660225},
file = {:home/etn/Documents/PhD/Biblio/Bartenstein, Liu - 2014 - Rate Types for Stream Programs.pdf:pdf},
isbn = {9781450325851},
journal = {Proceedings of the 2014 ACM International Conference on Object Oriented Programming Systems Languages and Applications},
keywords = {called data streams,data processing rates,data throughput,figure 1,items,large sequence of data,performance reasoning,rate,stream,stream programming,throughput ratio and natural,type systems},
pages = {213--232},
title = {{Rate Types for Stream Programs}},
url = {http://dl.acm.org/citation.cfm?id=2660225},
year = {2014}
}
@article{XU2015,
author = {XU, LE},
file = {:home/etn/Documents/PhD/Biblio/XU - 2015 - Stela ondemand elasticity in distributed data stram processing systems.pdf:pdf},
title = {{Stela: ondemand elasticity in distributed data stram processing systems}},
url = {http://dprg.cs.uiuc.edu/docs/le{\_}msthesis/StelaThesis.pdf},
year = {2015}
}
@article{Arasu2005,
author = {Arasu, Arvind and Babu, Shivnath and Widom, Jennifer},
doi = {10.1007/s00778-004-0147-z},
file = {:home/etn/Documents/PhD/Biblio/Arasu, Babu, Widom - 2005 - The CQL continuous query language semantic foundations and query execution.pdf:pdf},
issn = {1066-8888},
journal = {The VLDB Journal},
keywords = {Continuous queries,Data streams,Query language,Query processing},
month = {jul},
number = {2},
pages = {121--142},
publisher = {Springer-Verlag New York, Inc.},
title = {{The CQL continuous query language: semantic foundations and query execution}},
url = {http://dl.acm.org/citation.cfm?id=1146461.1146463},
volume = {15},
year = {2005}
}
@article{Arasu2003,
abstract = {The STREAM project at Stanford is developing a general-purpose system for processing continuous queries over multiple continuous data streams and stored relations. It is designed to handle high-volume and bursty data streams with large numbers of complex continuous queries. We describe the status of the system as of early 2003 and outline our ongoing research directions.},
author = {Arasu, Arvind and Babcock, Brian and Babu, Shivnath and Datar, Mayur and Ito, Keith and Motwani, Rajeev and Nishizawa, Itaru and Srivastava, Utkarsh and Thomas, Dilys and Varma, Rohit and Widom, Jennifer},
doi = {10.1145/872757.872854},
file = {:home/etn/Documents/PhD/Biblio/Arasu et al. - 2003 - STREAM The Stanford Stream Data Manager.pdf:pdf},
isbn = {158113634X},
issn = {07308078},
journal = {IEEE Data Engineering Bulletin},
number = {March 2003},
pages = {19--26},
pmid = {622423},
title = {{STREAM: The Stanford Stream Data Manager}},
url = {http://ilpubs.stanford.edu:8090/583/1/2003-21.pdf},
volume = {26},
year = {2003}
}
@inproceedings{Lerner2003,
abstract = {An order-dependent query is one whose result (interpreted as a multiset) changes if the order of the input records is changed. In a stock-quotes database, for instance, retriev- ing all quotes concerning a given stock for a given day does not depend on order, because the collection of quotes does not depend on order. By contrast, finding a stock’s five- price moving-average in a trades table gives a result that depends on the order of the table. Query languages based on the relational data model can handle order-dependent queries only through add-ons. SQL:1999, for instance, has a new “window” mechanism which can sort data in limited parts of a query. Add-ons make order-dependent queries difficult to write and to optimize. In this paper we show that order can be a natural property of the underlying data model and algebra. We introduce a new query language and algebra, called AQuery, that supports order from-the- ground-up. New order-related query transformations arise in this setting. We show by experiment that this framework – language plus optimization techniques – brings orders-of- magnitude improvement over SQL:1999 systems on many natural order-dependent queries.},
author = {Lerner, Alberto and Shasha, Dennis},
booktitle = {Proceedings of the 29th international conference on Very large data bases-Volume 29},
file = {:home/etn/Documents/PhD/Biblio/Lerner, Shasha - 2003 - Aquery Query language for ordered data, optimization techniques, and experiments.pdf:pdf},
isbn = {0127224424},
month = {sep},
pages = {345--356},
publisher = {VLDB Endowment},
title = {{Aquery: Query language for ordered data, optimization techniques, and experiments}},
url = {http://dl.acm.org/citation.cfm?id=1315451.1315482 http://portal.acm.org/citation.cfm?id=1315482{\&}amp;dl=GUIDE,},
year = {2003}
}
@article{Zaharia2010,
author = {Zaharia, M and Chowdhury, M},
file = {:home/etn/Documents/PhD/Biblio/Zaharia, Chowdhury - 2010 - Spark cluster computing with working sets.pdf:pdf},
journal = {HotCloud'10 Proceedings of the 2nd USENIX conference on Hot topics in cloud computing},
title = {{Spark: cluster computing with working sets}},
url = {http://static.usenix.org/legacy/events/hotcloud10/tech/full{\_}papers/Zaharia.pdf http://www.usenix.org/event/hotcloud10/tech/full{\_}papers/Zaharia.pdf},
year = {2010}
}
@article{Gunda2010,
abstract = {Managing data and computation is at the heart of datacenter computing. Manual management of data can lead to data loss, wasteful consumption of storage, and laborious bookkeeping. Lack of proper management of computation can result in lost opportunities to share common computations across multiple jobs or to compute results incrementally. Nectar is a system designed to address the aforementioned problems. It automates and unifies the management of data and computation within a datacenter. In Nectar, data and computation are treated interchangeably by associating data with its computation. Derived datasets, which are the results of computations, are uniquely identified by the programs that produce them, and together with their programs, are automatically managed by a datacenter wide caching service. Any derived dataset can be transparently regenerated by re-executing its program, and any computation can be transparently avoided by using previously cached results. This enables us to greatly improve datacenter management and resource utilization: obsolete or infrequently used derived datasets are automatically garbage collected, and shared common computations are computed only once and reused by others. This paper describes the design and implementation of Nectar, and reports on our evaluation of the system using analytic studies of logs from several production clusters and an actual deployment on a 240-node cluster.},
author = {Gunda, Pradeep Kumar and Ravindranath, Lenin and Thekkath, Chandramohan a and Yu, Yuan and Zhuang, Li},
file = {:home/etn/Documents/PhD/Biblio/Gunda et al. - 2010 - Nectar Automatic Management of Data and Computation in Datacenters.pdf:pdf},
isbn = {978-1-931971-79-9},
journal = {Technology},
pages = {1--8},
title = {{Nectar : Automatic Management of Data and Computation in Datacenters}},
url = {https://www.usenix.org/legacy/event/osdi10/tech/full{\_}papers/Gunda.pdf http://www.usenix.org/event/osdi10/tech/full{\_}papers/Gunda.pdf},
year = {2010}
}
@article{Murray2013,
abstract = {Naiad is a distributed system for executing data parallel, cyclic dataflow programs. It offers the high throughput of batch processors, the low latency of stream processors, and the ability to perform iterative and incremental computations. Although existing systems offer some of these features, applications that require all three have relied on multiple platforms, at the expense of efficiency, maintainability, and simplicity. Naiad resolves the complexities of combining these features in one framework. A new computational model, timely dataflow, underlies Naiad and captures opportunities for parallelism across a wide class of algorithms. This model enriches dataflow computation with timestamps that represent logical points in the computation and provide the basis for an efficient, lightweight coordination mechanism. We show that many powerful high-level programming models can be built on Naiad's low-level primitives, enabling such diverse tasks as streaming data analysis, iterative machine learning, and interactive graph mining. Naiad outperforms specialized systems in their target application domains, and its unique features enable the development of new high-performance applications.},
address = {New York, New York, USA},
author = {Murray, Derek G. and McSherry, Frank and Isaacs, Rebecca and Isard, Michael and Barham, Paul and Abadi, Martin},
doi = {10.1145/2517349.2522738},
file = {:home/etn/Documents/PhD/Biblio/Murray et al. - 2013 - Naiad.pdf:pdf},
isbn = {9781450323888},
journal = {Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles - SOSP '13},
month = {nov},
pages = {439--455},
publisher = {ACM Press},
title = {{Naiad}},
url = {http://dl.acm.org/citation.cfm?id=2517349.2522738 http://dl.acm.org/citation.cfm?id=2522738$\backslash$nhttp://dl.acm.org/citation.cfm?doid=2517349.2522738},
year = {2013}
}
@inproceedings{Xin2013,
address = {New York, New York, USA},
author = {Xin, Reynold S. and Rosen, Josh and Zaharia, Matei and Franklin, Michael J. and Shenker, Scott and Stoica, Ion},
booktitle = {Proceedings of the 2013 international conference on Management of data - SIGMOD '13},
doi = {10.1145/2463676.2465288},
file = {:home/etn/Documents/PhD/Biblio/Xin et al. - 2013 - Shark.pdf:pdf},
isbn = {9781450320375},
keywords = {data warehouse,databases,hadoop,machine learning,shark,spark},
month = {jun},
pages = {13},
publisher = {ACM Press},
title = {{Shark}},
url = {http://dl.acm.org/citation.cfm?id=2463676.2465288},
year = {2013}
}
@article{Tolooee2015,
author = {Tolooee, Cameron and Malensek, Matthew and Pallickara, Sangmi Lee},
doi = {10.1002/cpe.3651},
file = {:home/etn/Documents/PhD/Biblio/Tolooee, Malensek, Pallickara - 2015 - A scalable framework for continuous query evaluations over multidimensional, scientific datasets.pdf:pdf},
issn = {15320626},
journal = {Concurrency and Computation: Practice and Experience},
month = {sep},
pages = {n/a--n/a},
title = {{A scalable framework for continuous query evaluations over multidimensional, scientific datasets}},
url = {http://doi.wiley.com/10.1002/cpe.3651},
year = {2015}
}
@inproceedings{Toshniwal2014,
address = {New York, New York, USA},
author = {Toshniwal, Ankit and Donham, Jake and Bhagat, Nikunj and Mittal, Sailesh and Ryaboy, Dmitriy and Taneja, Siddarth and Shukla, Amit and Ramasamy, Karthik and Patel, Jignesh M. and Kulkarni, Sanjeev and Jackson, Jason and Gade, Krishna and Fu, Maosong},
booktitle = {Proceedings of the 2014 ACM SIGMOD international conference on Management of data - SIGMOD '14},
doi = {10.1145/2588555.2595641},
file = {:home/etn/Documents/PhD/Biblio/Toshniwal et al. - 2014 - Storm@ twitter.pdf:pdf},
isbn = {9781450323765},
keywords = {real-time query processing,stream data management},
month = {jun},
pages = {147--156},
publisher = {ACM Press},
title = {{Storm@ twitter}},
url = {http://dl.acm.org/citation.cfm?id=2595641 http://dl.acm.org/citation.cfm?id=2588555.2595641},
year = {2014}
}
@inproceedings{Madsen2015,
address = {New York, New York, USA},
author = {Madsen, Kasper Grud Skat and Zhou, Yongluan},
booktitle = {Proceedings of the 24th ACM International on Conference on Information and Knowledge Management - CIKM '15},
doi = {10.1145/2806416.2806449},
file = {:home/etn/Documents/PhD/Biblio/Madsen, Zhou - 2015 - Dynamic Resource Management In a Massively Parallel Stream Processing Engine.pdf:pdf},
isbn = {9781450337946},
keywords = {elasticity,fault-tolerance,resource management},
month = {oct},
pages = {13--22},
publisher = {ACM Press},
title = {{Dynamic Resource Management In a Massively Parallel Stream Processing Engine}},
url = {http://dl.acm.org/citation.cfm?id=2806416.2806449},
year = {2015}
}
@article{Sun2015,
abstract = {In the big data era, big data stream computing, as a computing paradigm, is gaining traction for real-time and online data computing applications, and is specially designed to solve the dilemma of real-time data stream computing by processing data online within real-time constraints. It is used to compute large amounts of data in the form of continuous data streams. Each computation is represented by a data stream graph, usually a directed graph. In this paper, the computing paradigm of big data stream computation in data stream graph is given, and some application scenarios and big data stream characteristics are presented. A series of challenges in designing a scalable big data stream computing system in big data environments are summarised by referring to some research results of big data stream computing system, which include stateless system architecture, elastically adaptive scheduling strategy and fine-grained fault tolerance strategy. All these challenges will greatly help us to understand big dat...},
author = {Sun, Dawei and Liu, Chunxiao and Ren, Dongfeng},
journal = {International Journal of Wireless and Mobile Computing},
keywords = {adaptive scheduling,big data stream computing,fine-grained fault tolerance,stateless system architecture,system design,task scheduling},
language = {en},
month = {oct},
publisher = {Inderscience Publishers (IEL)},
title = {{Prospects, challenges and latest developments in designing a scalable big data stream computing system}},
url = {http://www.inderscienceonline.com/doi/abs/10.1504/IJWMC.2015.072567},
year = {2015}
}
@article{Thusoo2009,
author = {Thusoo, Ashish and Sarma, Joydeep Sen and Jain, Namit and Shao, Zheng and Chakka, Prasad and Anthony, Suresh and Liu, Hao and Wyckoff, Pete and Murthy, Raghotham},
doi = {10.14778/1687553.1687609},
issn = {21508097},
journal = {Proceedings of the VLDB Endowment},
month = {aug},
number = {2},
pages = {1626--1629},
publisher = {VLDB Endowment},
title = {{Hive}},
url = {http://dl.acm.org/citation.cfm?id=1687553.1687609},
volume = {2},
year = {2009}
}
@article{Olston2008,
abstract = {There is a growing need for ad-hoc analysis of extremely large data sets, especially at internet companies where inno- vation critically depends on being able to analyze terabytes of data collected every day. Parallel database products, e.g., Teradata, offer a solution, but are usually prohibitively ex- pensive at this scale. Besides, many of the people who ana- lyze this data are entrenched procedural programmers, who find the declarative, SQL style to be unnatural. The success of the more procedural map-reduce programming model, and its associated scalable implementations on commodity hard- ware, is evidence of the above. However, the map-reduce paradigm is too low-level and rigid, and leads to a great deal of custom user code that is hard to maintain, and reuse. We describe a new language called Pig Latin that we have designed to fit in a sweet spot between the declarative style of SQL, and the low-level, procedural style of map-reduce. The accompanying system, Pig, is fully implemented, and compiles Pig Latin into physical plans that are executed over Hadoop, an open-source, map-reduce implementation. We give a few examples of how engineers at Yahoo! are using Pig to dramatically reduce the time required for the develop- ment and execution of their data analysis tasks, compared to using Hadoop directly. We also report on a novel debugging environment that comes integrated with Pig, that can lead to even higher productivity gains. Pig is an open-source, Apache-incubator project, and available for general use.},
address = {New York, New York, USA},
author = {Olston, Christopher and Reed, Benjamin and Srivastava, Utkarsh and Kumar, Ravi and Tomkins, Andrew},
doi = {10.1145/1376616.1376726},
file = {:home/etn/Documents/PhD/Biblio/Olston et al. - 2008 - Pig Latin A Not-So-Foreign Language for Data Processing.pdf:pdf},
isbn = {978-1-60558-102-6},
issn = {07308078},
journal = {Proceedings of the 2008 ACM SIGMOD international conference on Management of data - SIGMOD '08},
keywords = {dataflow language,pig latin},
month = {jun},
pages = {1099},
publisher = {ACM Press},
title = {{Pig Latin: A Not-So-Foreign Language for Data Processing}},
url = {http://dl.acm.org/citation.cfm?id=1376616.1376726},
year = {2008}
}
@article{Thies2002,
abstract = {We characterize high-performance streaming applications as a new and distinct domain of programs that is becoming increasingly im- portant. The StreamIt language provides novel high-level representations to improve programmer productivity and program robustness within the streaming domain. At the same time, the StreamIt compiler aims to im- prove the performance of streaming applications via stream-specific anal- yses and optimizations. In this paper, we motivate, describe and justify the language features of StreamIt, which include: a structured model of streams, a messaging system for control, a re-initialization mechanism, and a natural textual syntax.},
author = {Thies, William and Karczmarek, Michal and Amarasinghe, Saman},
doi = {10.1007/3-540-45937-5},
file = {:home/etn/Documents/PhD/Biblio/Thies, Karczmarek, Amarasinghe - 2002 - StreamIt A language for streaming applications.ps:ps},
isbn = {3540433694},
issn = {0302-9743},
journal = {Compiler Construction},
pages = {179--196},
title = {{StreamIt: A language for streaming applications}},
url = {http://link.springer.com/chapter/10.1007/3-540-45937-5{\_}14 http://rtsys.informatik.uni-kiel.de/svn/teaching/sem/11ss-conc/dkr/11ss-conc-dkr-talk.pdf http://www.springerlink.com/index/LC5B77HWR8J2UBHK.pdf$\backslash$nhttp://groups.csail.mit.edu/commit/papers/02/stream},
volume = {LNCS 2304},
year = {2002}
}
@article{Zaharia2012a,
abstract = {We present Resilient Distributed Datasets (RDDs), a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a fault-tolerant manner. RDDs are motivated by two types of applications that current computing frameworks handle inefficiently: iterative algorithms and interactive data mining tools. In both cases, keeping data in memory can improve performance by an order of magnitude. To achieve fault tolerance efficiently, RDDs provide a restricted form of shared memory, based on coarse-grained transformations rather than fine-grained updates to shared state. However, we show that RDDs are expressive enough to capture a wide class of computations, including recent specialized programming models for iterative jobs, such as Pregel, and new applications that these models do not capture. We have implemented RDDs in a system called Spark, which we evaluate through a variety of user applications and benchmarks.},
archivePrefix = {arXiv},
arxivId = {EECS-2011-82},
author = {Zaharia, Matei and Chowdhury, Mosharaf and Das, Tathagata and Dave, Ankur},
doi = {10.1111/j.1095-8649.2005.00662.x},
eprint = {EECS-2011-82},
file = {:home/etn/Documents/PhD/Biblio/Zaharia et al. - 2012 - Resilient distributed datasets a fault-tolerant abstraction for in-memory cluster computing.pdf:pdf},
isbn = {978-931971-92-8},
issn = {00221112},
journal = {NSDI'12 Proceedings of the 9th USENIX conference on Networked Systems Design and Implementation},
month = {apr},
pages = {2--2},
pmid = {2011},
publisher = {USENIX Association},
title = {{Resilient distributed datasets: A fault-tolerant abstraction for in-memory cluster computing}},
url = {http://dl.acm.org/citation.cfm?id=2228298.2228301 https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final138.pdf},
year = {2012}
}
@article{Upadhyaya2007,
abstract = {This paper presents Aspen, a high-level programming language thattargets both high-productivity programming and runtime support formanaging resources needed by a computation. Programs in Aspen arerepresented as directed graphs, where the edges are well-definedunidirectional ...},
address = {New York, New York, USA},
author = {Upadhyaya, Gautam and Pai, Vijay S. and Midkiff, Samuel P.},
doi = {10.1145/1229428.1229433},
file = {:home/etn/Documents/PhD/Biblio/Upadhyaya, Pai, Midkiff - 2007 - Expressing and exploiting concurrency in networked applications with aspen.pdf:pdf},
isbn = {9781595936028},
journal = {Proceedings of the 12th ACM SIGPLAN symposium on Principles and practice of parallel programming - PPoPP '07},
keywords = {net-,parallel programming,programming languages,resource management,work servers},
month = {mar},
pages = {13},
publisher = {ACM Press},
title = {{Expressing and exploiting concurrency in networked applications with aspen}},
url = {http://dl.acm.org/citation.cfm?id=1229428.1229433 http://portal.acm.org/citation.cfm?doid=1229428.1229433},
year = {2007}
}
