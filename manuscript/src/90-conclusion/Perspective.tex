\section{Perspectives} \label{chapter6:perspective}

As stated previously, static analysis impacts productivity to favor efficiency.
% For example, to isolate fluxions, the current implementation of the compiler restrains the developer to use only \textit{in situ} callbacks, and avoids aliasing.
Though, an interesting perspective to continue this work is to implement the equivalence as a just-in-time compiler.
Indeed, the dynamic analysis allowed at run time is more prone to overcome the limitation identified with static analysis.

\subsection{Just-in-time Compilation}

Most Javascript interpreters compile some parts of the code at run time to improve performances.
During this compilation, the levels of indirections are mostly resolved.
The code is translated directly into lower-level instructions.

Implementing the equivalence in a just-in-time (JIT) compiler could leverage this dynamic resolution.
It could analyze the scope of variables resolved dynamically, and isolate the stages accordingly.

\paragraph{Rupture point detection}

The asynchronous functions identifying rupture points are not part of Javascript.
They are special functions provided by the interpreter.
With the compiler communicating with the interpreter at run time, detecting rupture points become trivial.
The interpreter notifies the compiler when an asynchronous function is called.
The compiler then identifies the rupture point and isolates it to possibly execute it remotely.

\paragraph{Dominator Tree}

To debug the memory in dynamic languages like Javascript, one can use a dominator tree.
It is a tree generated at run time indicating the parenting relations between memory objects.
With such a tree, the analysis of interdependencies between stages becomes trivial.
Each stage can be isolated in a fluxion, and deployed accordingly to its dependencies.

% With the dynamic registering of Fluxions to the messaging system, and into tag groups, it is possible to transform a Javascript application continuously during its execution.
% Analysis of the interdependencies become as trivial as for static languages, with the resolution of the indirections by the just-in-time compiler.
% The fluxional compiler waits for these resolutions, and then analyzes the compiled code for rupture points.
% As the asynchronism of a function call is handled by the execution engine, the just-in-time compilation can pin point precisely the asynchronous calls from the synchronous ones. 
% And the continuations for these asynchronous calls are resolved, which makes them similar to inline continuations.

\paragraph{Closure Serialization}

Closures are required to allow higher-order programming.
But the static compiler is unable to manipulate closures, as illustrated in section \ref{chapter5:flx:evaluation:isolation}.
Closures are generated dynamically by the interpreter.
With the compiler communicating with the interpreter, the former can manipulates and serialize them at run time.
It can then send closures between fluxions, like any other objects.
It enables the use of higher-order programming within the fluxional execution model.
Hence, it would allow, to some extent, to improve the compromise between productivity and efficiency.
Indeed, the developer is free to use the higher-order programming to compose modules, with a global memory abstraction.
Yet, the execution could distribute this global memory abstraction according to the detected interdependencies.

\paragraph{Dynamic Grouping}

With the dynamic detection of stages and their dependencies, and the manipulation of closures, fluxions can be registered during the execution of the application.
To assure they meet their dependencies, the fluxions are deployed according to their groups.
Two fluxions belong to the same group if they need to share access to some variables.
Therefore, they need to be deployed on the same event-loop to share their memory.

\paragraph{Safe-Checking}

It is required to safe-check that the compiled code is consistent with the remaining execution.
As an example, just-in-time compilers check the type to assure that a compiled function remains conform to the input and output types of its call site.
Similarly, it is required to check that the deployment of fluxions doesn't cause inconsistencies.

If a fluxion ready to be deployed belongs to two different groups, these two groups needs to be gathered on the same event-loop.
If they were previously deployed on two different event-loops, they need to be moved with their context to be on the same event-loop.
Moreover, to assure consistency, they need to be moved when receiving the request that triggered the fluxion ready to be deployed.
So that when this new fluxion is executed at this message reception it has access to the contexts of the two groups.
For this purpose, the compiler put the execution on hold, and sends a control message downstream to order the move of the fluxions.
% It interleaves control messages in the stream to communicate with the distributed interpreters.
In this example, the message inquired the distributed interpreters to stop execution, pack the fluxions and their contexts, and send them back to another remote interpreter.
To assure consistency, the execution resumes only when all the fluxions are gathered in the same event-loop, with access to the whole shared memory.

% If the new fluxion depends an a local variable, as well as a variable from a group on another node than the local node, the group needs to be deployed back locally.
% The fluxion as well as all the fluxions of the group are deployed locally, but the execution needs to wait for the contexts of the group to be available locally.
% To gather the contexts, the node responsible for this group send a message to the messaging system managing this group.
% The messaging system gather all the contexts of the fluxions, and send them back.
% When the contexts are deployed locally to the new node responsible for the this group, the execution of this branch can resume.

% A new compromise have to be done between the cost of sending a fluxion and the cost to get it back, and the risk that it requires to be sent back.
% It might be possible to reduce this risk by saving the compilation information from one execution to the other.

\separator

The perspectives described in the previous paragraphs overcome the limitations of the current implementation of the compiler.
They describe the further implementation of the equivalence, as if I were to continue this work.

\subsection{Evaluation of the perspective}

This second evaluation admits that the JIT compilation resolves all the indirections in the memory.
% Which is left unknown after this thesis.
Then, the fluxional JIT compiler doesn't need to rely on human interaction.
Therefore, the expected productivity is the same as the productivity language used as source. %, as illustrated in table \ref{tab:perspective-productivity}.

% \TablePerspectiveProductivity{tab:perspective-productivity}

Naturally, the performance efficiency of the implementation is, at first, the same of this productivity language, as the development is focused on productivity.
Some development efforts are required to improve the efficiency.
% But the result of the compilation helps in this shift.
The result from the compiler helps the developer find the bottle necks, and reduce the effort for this shift.
With the help from the compiler, the effort for this shift is expected to be less than the current required effort.
% The effort for this shift are expected to be less than the current required effort. %, as illustrated in table \ref{tab:perspective-efficiency}.
Instead of redesigning the architecture of the application to immediately isolate components, it is possible to modify them to progressively loosen their dependencies.
As illustrated in table \ref{tab:perspective-summary}, this envisioned platform is expected to yield both productivity and efficiency, not at the same time, but when they are required the most.

% \TablePerspectiveEfficiency{tab:perspective-efficiency}

Moreover, during this decomposition and after, developers can still rely on higher-order programming, even between isolated application parts.
In the current state of the art, there is no known platform to offer higher-order programming between distributed parts.
This possibility is therefore unknown, and could actually yield to an unrivaled compromise between productivity and efficiency.

Following the insight along this thesis, a platform bringing both productivity and efficiency simultaneously would be greatly adopted.
But it requires to be observed in real conditions before drawing this conclusion.
% , as illustrated in table \ref{tab:perspective-adoption}.

% \TablePerspectiveAdoption{tab:perspective-adoption}
% \separator

\TablePerspectiveSummary{tab:perspective-summary}

\subsection{Final Thoughts}

As I studied for this thesis, I progressively opened my vision on the world.
And as a final note in this thesis, I would like to share this vision.

\paragraph{Economic Considerations}

The IT industry understood that trading efficiency for productivity could reduce development time and cost, and hardware performance could compensate.
This thesis intends to bring a reconciliation between two economical concerns in the development of a web application, the efficiency of execution and the productivity of development.
I believe that it is time to take into account both productivity and efficiency.

The IT industry has an important impact on the environment with its increasing carbon footprint.
As the digitalization permeates into every aspects of our lives, it is of crucial importance to consider this impact.
Therefore, it is time to reduce the efficiency to the minimum required.
Yet, with the increasing importance of the IT, development cannot be reserved to experts anymore.
Productivity cannot be traded back for efficiency.

% I leave for future works the reconciliation of the efficiency of energy consumption with the two concerns addresses in this thesis.
% Like with ThinkAir and Maui, whete the code offloading can helps to save energy on the mobile \cite{Kosta2012,Cuervo2010a}.

\paragraph{Accessible And Omnipresent Development}

This epoch feels like developers are the scribes and the monks after the invention of writing.
I believe that in the time to come, development will be made available for everybody.
And additionally as reading and writing, developing will be a prerequisite to communicate with peers.
It will allow to express dynamic behaviors, and not only static ones, as Bret Viktor already envisioned\ftnt{https://vimeo.com/115154289}.

This shift might come with the increasing importance of machine learning.
Indeed, it allows to define complex dynamic behaviors without specifically describing every corner cases.
It feels like the composition of general case behavior that can seamlessly meld at corner cases.
If machine learning can become parts of our daily means of communication, it will radically change our interactions with peers, and with the world.

Moreover, with the advent of the smart contracts based on block chain technology, and the Internet of things, it is not far-fetched to imagine our everyday world infused with behaviors defined by others.
I believe the difference between a person and its environment will start to dissolve.
A limited preview can be drawn in our dependence to Internet, smart-phones and other connected objects.
But the possibilities are beyond our current imagination.

\paragraph{Scalability}

At the light of this thesis, I understand that scalability boils down to the choice of an organization.
The chosen organization determines what should be kept local, versus, what should be spread globally.
I believe the same problematic applies to many different everyday organizations, such as economical and social organizations.

For example, in economy, it is important for certain markets to spread globally.
The different international markets, such as stocks and foreign currency exchange market, are crucial to spread economical informations worldwide.
The variations of prices on these markets yields the informations to direct the consumption and production of every product and raw materials for the entire population.
It avoids spoiling resources.
On the contrary, the uncontrolled variations of this global economy can be destructive at a wide scale, and must somehow be contained.
Local citizen currency is an example of such containment.
It contains the scope of these variations within a local region.

To concludes this thesis, I yield the following problematic.
How to layout the organizations composing our everyday world for it to be efficient.
Economically, socially, and in many other aspect of our everyday lives, I believe designing an efficient organization boils down to choosing which piece of information shall be kept locally, or spread globally.