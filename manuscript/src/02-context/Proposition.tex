\section{Proposition} \label{chapter2:proposition}

In the previous section, I presented two implementation organizations to improve either performance scalability, or development scalability.
However, these two organizations are incompatible, which imply ruptures in the development.
This thesis argues that a compiler should bridge the gap between the two organizations, so as to allow a continuous development.
This section presents the two programming models representing each an organization.
Then it presents the possibility of an equivalence between the two.
This equivalence is detailed further in the the chapter \ref{chapter4} and \ref{chapter5} of this thesis.

% I argue that the language should propose to the developer an abstraction to encourage the best practices of software development.
% Then a compiler, or the execution engine, can adapt this abstraction so as to leverage parallel architectures. 
% So as to provide to the developer a usable, yet efficient compromise.
% We propose to find an equivalence between the invariance proposed by the cooperative scheduling paradigm and the invariance proposed by the multi-processes paradigm in the case of web applications.

\subsection{Architecture of web applications}

\subsubsection{Real-time streaming web services}

% \nt{The need for invariance in the streaming applications : it can be emulated by message passing. Indeed the data flows from one processing step to the other, with few retroprogation of state (don't mention retro-propagation yet)}

We focus on web applications processing streams of requests from users in soft real-time.
Such applications receive requests from clients using the HTTP protocol and must respond within a finite window of time.
They are generally organized as sequences of tasks to modify the input stream of requests to produce the output stream of responses.
The stream of requests flows through the tasks, and is not stored.
% This stream of data stand out from the state of the application.
On the other hand, the state of the application remains in memory to impact the future behaviors of the application.
This state might be shared by several tasks within the application, and imply coordination between them.
% In this thesis I study two programming paradigm derived directly from the cooperative scheduling and the multi-process paradigms presented in previous sections to be applied in the case of real-time web applications.

The next paragraphs present two programming models to express web applications based on the invariance paradigms presented in the previous section.
%, the event-loop and the pipeline architecture.
The event-loop execution engine is based on the cooperative scheduling, and the pipeline architecture is based on isolated tasks communicating by message passing.
% They both feature different organization for the sequence of tasks, the stream and the state.
This thesis is based on the similarities between these two programming models.

\subsubsection{Event-loop}

The event-loop is an efficent execution model for concurrent applications on a single processing unit using non-blocking communications.
It relies on a queue storing the received messages before being processed one after the other by the loop.
On each reception, the loop executes a task to process the received message.
% This event is the aggregation of the response, and of a function to continue the execution with the result.
While processing the message, the task can initiate new communications, leading in turn to the queuing of more messages, which trigger more tasks, and so on.
The scheduling of execution is cooperative, each task is executed atomically and exclusively, until it yields execution, to continue with the next task in queue.


% The tasks are scheduled cooperatively, and yield execution on asynchronous communication.

In Javascript, these tasks are defined during the communication initiation.
The function called to initiate the execution expects as argument a function to continue the execution at the reception of communication result.
This function is called a callback or a continuation.

In this model, the input stream of data flows through a sequence of callbacks to be processed until the application outputs it.
This stream is never stored, except as a buffer between two callbacks.
On the contrary, The state ramins in memory to be shared by all callbacks.
Because Javascript is of higher-order, the callbacks as well as their execution contexts are part of this state.
They are called closures.
% In Javascript, it includes the closures.

\nt{TODO schema of an event-loop}

This execution model is similar to the pipeline architecture presented in the next paragraph.

\subsubsection{Pipeline}

The pipeline software architecture is composed of isolated stages communicating by message passing to leverage the parallelism of a multi-core hardware architectures.
It is well suited for streaming application, as the stream of data flows from stage to stage.
Each stage has an independent memory to hold its own state.
As the stages are indendent, the state coordination between the stages are communicated along with the stream of data.

\nt{TODO schema of a pipeline}

Each stage is organized in a similar fashion than the event-loop presented above.
It receives and queues messages from upstream stages, processes them one after the other, and outputs the result to downstream stages.
The difference is that in the pipeline architecture, each task is executed on an isolated stage, whereas in the event-loop execution model, all tasks share the same queue, loop and memory store.

Both paradigms encapsulate the execution in tasks assured to have an exclusive access to the memory.
However, they provide two different models to provide this exclusivity resulting in two distinct ways for the developer to assure the invariance on the application state.
Contrary to the pipeline architecture, the event-loop provide a common memory store allowing the best practice of software development to improve maintainability.
It is possibly the reason of the wide adoption of this programming model by the community of developers.

\paragraph{}

This thesis proposes to provide an equivalence between the two memory models for streaming web applications.
The next subsection describes further the similarities and differences between the two models.
The equivalence would allow a compiler to transform an application expressed in one model into the other.
With such a tool, a development team could rely on the common memory store of the event-loop execution model, and focus on the maintainability of the implementation.
And compile continuously during the development the event-loop implementation to the pipeline architecture to assure that the execution can be distributed on a parallel architecture.

\subsection{Equivalence}

\subsubsection{Rupture point}

The execution of the pipeline architecture is well delimited in isolated stages.
Each stage has its own thread of execution, and is independent from the others.
On the contrary, the code of the event-loop is linear because of the continuation passing style and the common memory store.
% The message passing linking the callbacks is transparently handled by the event-loop.
However, the execution of the different callbacks are as distinct as the execution of the different stages of a pipeline.
The call stacks of two callbacks are distincts.
Therefore, an asynchronous function call represents the rupture between two call stacks.
It is a rupture point, and is equivalent to a data stream between two stages in the pipeline architecture.

Both the pipeline architecture and the event-loop present these rupture points.
The detection of rupture points allows to map a pipeline architecture onto the implementation following the event-loop model.
To allow the transformation from one to the other, this thesis studies the possibility to detect rupture points, and to distribute the global memory into the parts defined by these rupture points.
The detection of rupture points is addressed in chapter \ref{chapter4}.

\subsubsection{Invariance}

% This transformation is important on two points.
% The conservation of the invariance.
% The equivalence between the coordinations.

The transformation should preserve the invariance as expressed by the developer to assure the correctness of the execution.
The partial ordering of events in a system, by opposition to total ordering, is sufficient to assure this correctness.
% This result was used by Lamport to prove the correctness of distributed systems.
The global memory is a way to assure the total ordering of events, and the message passing coordination is a way to assure partial ordering of events.
Therefore, to assure the correctness of the execution of a system, the state coordination with a global memory is equivalent to message passing coordination.
And it is possible, at least for some rupture points, to transform the global memory coordination into message passing while conserving the correctness of execution.

In order to preserve the invariance assured by the event-loop model after the transformation, each stage of the pipeline needs to have an exclusive access to memory.
The global memory needs not to be splited into parts and distributed into each of the stages.
To assure the missing coordinations assured by the shared memory between the stages, the transformation should provide equivalent coordination with message passing.
The isolation and replacement of the global memory is fully address in chapter \ref{chapter5}

% The invariance holds for the whole memory during the execution of each callback.
% As I explained in the previous section, this invariance is required to allow the concurrent execution of the different tasks.
% On the other hand, the invariance is explicit in the pipeline architecture, as all the stages have isolated memories.
% The coordination between these isolated process is made explicit by the developer through message passing.

% I argue that the state coordination between the callbacks requireing a global memory could be replaced by the message passing coordination used manually in the pipeline architecture.
% I argue that not all applications need concurrent access on the state, and therefore, need a shared memory.
% % Specifically, I argue that each state region remains roughly local to a stage during its modification.
% \nt{TODO review that, I don't know how to formulate these paragraphs. Identify the state and the data in the global memory.}

% \subsubsection{Transformation}

% This equivalence should allow the transformation of an event loop into several parallel processes communicating by messages.
% In this thesis, I study the static transformation of a program, but the equivalence should also hold for a dynamic transformation.
% I present the analyzis tools I developed to identify the state and the data from the global memory.

With this compiler, it would be possible to express an application following the design principles of software development, hence maintainable.
And yet, the execution engine could adapt itself to any parallelism of the computing machine, from a single core, to a distributed cluster.
Because of the equivalence between these two models, the development team could iterate testing the two models for their different concerns about the implementation : performance and maintainability.

The goal of conciling these two concerns is not new.
The next chapter presents all the results from previous works needed to understand this work, up to the latest results in the field.

\endinput




---


There are different kinds of state dependencies in applications components leading to different kinds of parallelism.
In this thesis I argue that it is possible to parallelize a real-time web applications written on an event-loop because the strong dependencies mainly remains within a closed number of concurrent executions.




\subsubsection{Learning curve}

Because the compiler intend to warn the developer about shared states, it would be a great tool for beginner to progressively adapt to the flow programming model and best practices.


\subsection{Liquid IT}

The goal of Liquid IT is to hide the technical complexity of scalability to the developer, so he can focus solely on business logic.


