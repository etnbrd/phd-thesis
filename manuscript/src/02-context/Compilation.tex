\section{Equivalence}

I argue that the language should propose to the developer an abstraction to encourage the best practices of software development.
Then a compiler, or the execution engine, can adapt this abstraction so as to leverage parallel architectures. 
So as to provide to the developer a usable, yet efficient compromise.
We propose to find an equivalence between the invariance proposed by the cooperative scheduling paradigm and the invariance proposed by the multi-processes paradigm in the case of web applications.

\subsection{Architecture of web applications}

\subsubsection{Real-time streaming web services}

\nt{The need for invariance in the streaming applications : it can be emulated by message passing. Indeed the data flows from one processing step to the other, with few retroprogation of state (don't mention retro-propagation yet)}

This equivalence intends not to be universal.
It focuses on a precise class of applications : web applications processing stream of requests from users in soft real-time.

Such applications are organized in sequences of concurrent tasks to modify the input stream of requests to produce the output stream of responses.
This stream of data stand out from the pure state of the application.
The data flows in a communication channel between different concurrent tasks, and is never stored on any task.
The state represents a communication channel between different instant in time, it remains in the memory to impact the future behaviors of the application.
The state might be shared by several tasks of the application, and result in the needs for coordination presented in the previous section.
In this thesis I study two programming paradigm derived directly form the cooperative scheduling and the multi-process paradigms presented in previous sections to be applied in the case of real-time web applications.
The event-loop execution engine is a direct application of the cooperative scheduling, and the pipeline architecture is a direct application of the multi-process paradigm.

\subsubsection{Event-loop}

The event-loop is an execution model using asynchronous communication and cooperative scheduling to allow efficent execution of concurrent tasks on a single processing unit.
It relies on a queue of event, and a loop to process each event one after the other.
The communications are asynchronous to let the application use the processor instead of waiting for a slow response.
When the response of a communication is available, it queues an event.
This event is composed of the result of the communication, and of a function previously defined at the communication initiation, to continue the execution with the result.
In the Javascript even-loop, this function is defined following the continuation passing style, and is named a callback.
After processing the result, this callback can initiate communications, resulting in the queuing of more events.

In this model, the data is the result of every communication operations - starting with the received user request - flowing through a sequence of callbacks, one after the other.
The state contains all the variables remaining in memory from one request to the other, and from one callback to the other.
In Javascript, it includes the closures.

\nt{TODO schema of an event-loop}

\subsubsection{Pipeline}

The pipeline software architecture uses the multi-process paradigm and message passing to leverage the parallelism of a multi-core hardware architectures for streaming application.
It consists of many processes treating and carrying the flow of data from stage to stage.
This flow of data consist roughly of the requests, and associated data from the user, as well as the necessary state coordination between the stages.
Each stage has its independent memory to hold its own state from one request to another.

\nt{TODO it is not universal, but multi-process paradigms are also oriented around event-loops. An Event-loop is a multi-process on one machine. A multi-process is multiple event-loop running different part of the same program.}

\nt{TODO schema of a pipeline}

The pipeline architecture and the event-loop model present similar execution model.
Both paradigms encapsulate the execution, in callbacks or processes.
Those containers are assured to have an exclusive access to the memory.
However, they provide two different memory models to provide this exclusivity.
It results in two distinct ways for the developer to assure the invariance, and to manage the global state of the application.
The event-loop shares the memory globally through the application, allowing the best practice of software development.
It is possibly the reason of the wide adoption of this programming model by the community of developers.

I argue in this thesis that it is possible to provide an equivalence between the two memory models for streaming web application.
In the next subsection, I present the similarity in the execution model, and the differences in the memory model for which an equivalence is necessary.
Such equivalence would allow to transform an application following the event-loop model to be compatible with the pipeline architecture.
This transformation would allow the development of an application following a programming model allowing the best practices of software development, while leverageing the parallelism of multi-core hardware architecture.

\subsection{Equivalence}

\subsubsection{Rupture point}

The execution of the pipeline architecture is well delimited in isolated stages.
Each stage has its own thread of execution, and is independent of the others.
On the other hand, the execution of the event-loop seems pretty linear to the developer.
The continuation passing style nest callbacks linearly inside each others.
The message passing linking the callbacks is transparently handled by the event-loop.
However, the execution of the different callbacks are as distinct as the execution of the different stages of a pipeline.
Precisely, the call stack is as distinct between two callbacks, as between two stages.
Therefore, in the event-loop, an asynchronous function call represents the end of the call stack of the current callback, and the beginning of the call stack of the next.
It represents what I call a rupture point.
It is the equivalent to a data stream between two stages in the pipeline architecture.

Both the pipeline architecture and the event-loop present these ruptures points.
To allow the transformation from the event-loop model to the pipeline architecture in the case of real-time web applications, I study in this thesis the possibility to transform the global memory of the event-loop into isolated memory to be able to execute the application on a pipeline architecture.

\subsubsection{State coordination}

The global memory used by the event-loop holds both the state and the data of the application.
The invariance holds for the whole memory during the execution of each callback.
As I explained in the previous section, this invariance is required to allow the concurrent execution of the different tasks.
On the other hand, the invariance is explicit in the pipeline architecture, as all the stages have isolated memories.
The coordination between these isolated process is made explicit by the developer through message passing.

I argue that the state coordination between the callbacks requireing a global memory could be replaced by the message passing coordination used manually in the pipeline architecture.
I argue that not all applications need concurrent access on the state, and therefore, need a shared memory.
Specifically, I argue that each state region remains roughly local to a stage during its modification.
\nt{TODO review that, I don't know how to formulate these paragraphs. Identify the state and the data in the global memory.}

\subsubsection{Transformation}

This equivalence should allow the transformation of an event loop into several parallel processes communicating by messages.
In this thesis, I study the static transformation of a program, but the equivalence should also hold for a dynamic transformation.
I present the analyzis tools I developed to identify the state and the data from the global memory.

With this compiler, it would be possible to express an application with a global memory, so as to follow the design principles of software development.
And yet, the execution engine could adapt itself to any parallelism of the computing machine, from a single core, to a distributed cluster.

\comment{TODO too fast on the end of this section}

\comment{TODO Transition to the chapter State of the Art}

\endinput




---


There are different kinds of state dependencies in applications components leading to different kinds of parallelism.
In this thesis I argue that it is possible to parallelize a real-time web applications written on an event-loop because the strong dependencies mainly remains within a closed number of concurrent executions.
