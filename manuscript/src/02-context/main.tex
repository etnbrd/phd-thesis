\chapter{Context and objectives}
\minitoc
\eject

\input{02-context/Web-as-a-platform}

Transition : the observation shows that most web applications are written in imperative languages, while the important web applications are written in a scalable ways.

\section{High concurrency web servers}

\subsection{Scalability}

Scalability is the ability for a web application to adapt its load to the demand in a reasonable time.

\subsection{Concurrency}

The web needs high concurrency servers, because there is a lot of simultaneous connections.
As examples, the C10K problem, and now the C10M problem.

\comment{It is important here to see a web service as a stream of requests. See Real Time Web services (last paragraph)}

Concurrency is a superset including different fashion.
TIme-slicing and parallelism.

\subsection{The different compromises}

To attain concurrency there is different alternatives.
- isolation in processes 
- thread share with lock
- global memory event loop concurrency

The first two are parallel, and can stretch on multiple cores, as well as be restrained on one.
However, the last one, because of the global memory, is restrained on one core.
Yet, we show that this model is easier to develop because of this global memory.

\subsection{Technological shift}

\subsubsection{Power wall}

Because of the power wall, time-slicing is a limited option.
The only viable option for high concurrency is parallelism.

\subsubsection{Rupture}

There is a performance problem with languages about concurrency.
The used imperative programming languages are difficulty parallel.
And the highly parallel programming languages are not largely used.

There is a technological rupture between the two.

\subsubsection{Economical consequences}

This problem imposes the development team of a web application to take risk to shift from one technology to the other.


\subsection{A problem of memory}

The problem highlighted by this shift is that parallelism requires isolation of memory, while developers are more effective with a global memory.

Parallelism is difficult for developers only because it implies to manage the coordination of state, either via isolation and messages, or sharing and locking.
And not because spawning threads is difficult, or that coordination between threads is difficult.

There is a need for a language that exposes the right abstraction to the developer, so that it is easy to develop, and yet parallelizable.

\subsubsection{Invariance}

We explore here the different ways to coordinate the state.
Particularly, what we call the invariance : how a developer is assured that its state is not corrupted by coordination.

For every of these compromises, the developer needs to know the invariance of the memory.
For isolated processes, it is trivial, the memory is exclusive.
For thread with locks, the invariance needs to be explicit for every piece of shared state. It is painful, and inefficient.
For event-loop, the invariant is assured because of the cooperative scheduling.

We show here that the different coordination mechanism are hard for the developer.

The previous attempt to provide such a language ignored the fact that developers needs a global memory. \comment{TODO argumentation please.}
We argue that it should be the other way around.
That the language should adapt to the developer, so that they can meet in a usable, yet efficient compromise.


\subsection{The case for global memory}

\subsubsection{Familiarity}

Developers are more familiar with a global memory.
\comment{TODO I need a strong argument here, or merge with another}

\subsubsection{Separation of concern}

Software craftmanship advocate a different kind of memory isolation.
There is a difference in that this isolation is not about coordination, but about separation of concerns.
- encapsulation
- Separation of concerns
- loose coupling
The problem to avoid is concurrent conflicting accesses on one hand, spaghetti code on the other.

\subsubsection{Granularity of abstraction}

Finally, the difference of memory isolation is the result of two different granularity of abstraction.

The granularity of the machine is not the same as the granularity of the program.
You hardly have the same number of request as the number of processors.
The developer wants to be presented with an abstract machine.

We argue that, provided the compiler to split the memory, an event-loop is a good fit for this abstract machine.
This abstract machine being the `good` representation for the developer of the underlying machine.


\subsection{Compilation from abstract representation}

We propose to study how to transform an event loop into isolated processes communicating by messages.

If the processes are cleanly isolated, they can share their memory to increase communication time when few resources are needed, or be distributed on multiple node when more resources are needed.

\subsubsection{Real-time web services}

Web applications are now written more in a stream fashion (the event loop is executed like a pipeline, react is kind of a pipeline as well)
Web services can be seen as pipelines processing streams of requests.
We target application that can be written in a stream fashion.

From USL, there are different kinds of dependencies in applications, with different coupling (from stateless, to state-full), leading to different kind of parallelism.

We believe that web applications can be expressed as a pipeline of stream.
And that states is not heavily shared between the stages of this pipeline.
Meaning, the global memory holding the states can be isolated into stages.

\subsubsection{State and Data}

See flx-paper


\section{Proposition}


\comment{TODO}


\endinput





\subsubsection{Performance reason}
Global memory increase performances when there is single threads.
Functional languages with immutability exists since a long time.
It allows a good memory isolation, and thus, parallelism.
But, if it is conceptually elegant \comment{please argument here}, it needs deep copies which is bad for performances.
The argument here is that when there is no parallelism, a global memory is better.
So the isolation of the memory should be driven by the need for actual parallelism, not potential parallelism.
So, the loss of performance due to copying, or wire transfer, is compensated by the parallelism.












\subsection{Liquid IT}

The goal of Liquid IT is to hide the technical complexity of scalability to the developer, so he can focus solely on business logic.







% But many large company replaced the initial languages of the web with scalable solutions.
% Twitter : Ruby -> Storm
% Facebook : PHP -> HHVM / Flux ...
% Google : MapReduce, Kubernetes, Borg ...






I think, there is not a decisive difference between the infrastructure and the language, Node.js, or the DOM are what placed Javascript where it is now.
And Erlang is a language, not an infrastructure, and yet, it suffers from the same problems than most infrastructures.
These corner cases make me believe the difference is not between language and infrastructure, but holds in two characteristics at the core of the interfaces proposed by languages or infrastructures.

The first characteristic is how the machine is represented by the language.
This characteristic, is indeed really close to the difference language infrastructure, as language tends to abstract the machine, while infrastructure tends to provide direct accesses for the developer.
Does the developer manipulate concrete representation of the underlying machine, like execution containers process, thread, actors, and so on ...
Or does it manipulate abstract representation, like a global key values store,memory, references, functions and so on ...

Are these representations continuous, or discrete ?

\paragraph{The representation of the execution}
A pool of thread is discrete, there is a finite number of thread.
While in a functional language, the number of function is more continuous.
Specifically, the number of functions / modules, depends only on the structure of the program and the needs of the developer.
A program can contains as many functions / modules as it needs, it doesn't impact the performance.
While the developer is more limited in the number of threads, because it directly impact the performances, or has incentives to deal with threads to augment the performance.

Concurrency is an abstract representation, it doesn't imply specifically that there are parallel executions, or time-sliced executions.
It simply express the dependencies between different steps in the execution.
Parallelism on the other hand tends to be a more concrete representation as it is intended to be executed simultaneously.

\paragraph{The representation of the memory}







Performances comes from one factor : parallelism.
The only factor that comes in play, is how a language / infrastructure present this parallelism to the developer.
Most choose to give direct access to the developer : actors, threads, process ... mostly infrastructures and erlang.
Other choose to give no access, at the cost of completely loosing parallelism : imperative languages without the infrastructure.

This parallelism needs to exploit tow aspects.
- execution representation : unique, multiple.
How the dependencies are expressed between operations.
- memory representation : global, isolated.
How the executions depends on the memory.

Unique execution, global memory : imperative

Multiple execution, global memory : threads

Unique execution, isolated memory : OOP ?

Multiple execution, isolated memory : Actors / process ...


We see that multiple executions are mostly a fail.
So the developer needs to have an abstract representation of an unique  execution, that will be split at compilation or execution.
See about the continuity (scalability) of the execution model.

To allow the split of execution, we needs hints about the dependencies between operations, both in term of causality, and in term of memory share.

Cooperative scheduling successfully allow to represent the dependencies between operations.

However, as soon as the developer is not aware anymore of the invariance, it fails, because it needs explicit synchronization (locks), which are a pain to manage.

Instead, I think the sweet spot is in letting the developer provide the invariance via cooperative scheduling.

"                               IMPORTANT                                     "
Multiple execution are difficult to manage, only because it implies to manage the coordination of state.
Either via isolation and messages, or sharing and locking.
"                                                                             "

\paragraph{The invariance}

The invariance, is how the language let the developer know the integrity of the memory, while still letting her choose points of rupture to allow parallelism.

There is a scale between explicit synchronization of variables (locks) and implicit atomicity of execution on the global memory (cooperative scheduling).
The granularity is not the same, in terms of execution and memory :

          execution                      memory
        ---------------------------------------------------------------
lock :    small granularity (region)     small granularity (variable)
coop :    large granularity (event)      large granularity (global memory)

what about the two other kind

          small granularity              large granularity     ->    ?
          large granularity (actor)      small granularity     ->  actors




Threads are pre-emptive.
Fibers, green threads and so on are pre-emptive. (they are cooperatively scheduled, but they don't let the developer know when they are cooperatively scheduled)
The event-loop is not.

Global memory :

The fundamental difference is in the control they allow to the developer.
The event-loop abstract some stuffs (to define, but basically the threads, or the scheduling), and gives access to other stuffs : the pre-emption.
The threads, green threads and so on abstract the pre-emption, while they give access to the granularity of parallel executions.

Because of this pre-emption, to assure the invariance, threads provided the solution of locks.
But it is difficult to manage and leads to deadlock.
It is a degenerated version of the solution of atomic execution provided by the event-loop : you have complete access on the memory, and you won't be pre-empted.

Isolated memory :

Actors and processes, like the threads, allow you to split the execution 

 gives you another kind of control on the memory






How the developer needs to protect the memory invariant from pre-emption in different concurrency models ?
  event-loop  |  thread  |   process
     none     |  locks   |  isolation

-> So when developers are in control of the pre-emption, they manage it safely.
(compared to when they have to assure locks, or isolation)


How parallelizable is the model ? So how scalable is it ?
  event-loop  |  thread  |   process
       0      |     +    |     +++

-> So isolated process are the way to go for parallelism.
(It is the only true parallelism indeed)

So the sweet spot is a compiler from event-loop to process.


Event-loop is perfect for real-time web application.
Application processing stream of data.
So it is possible to compile real time web application using-event loops into chain of processes.



Explosion of Javascript popularity

Turn-based programming
  -> Javascript is turn based, it is a better solution than threads, and process for concurrency.






\begin{center}
\rule{4cm}{0.4pt}\\
old stuffs\\
\rule{4cm}{0.4pt}
\end{center}



\subsection{Separation of concerns}


% I see a trend here.
% http://pchiusano.blogspot.fr/2010/01/actors-are-not-good-concurrency-model.html

The languages presented in the last section all have large developing community. Some are functional, others are object-oriented.

To answer the first question.
If a module is limited inside an actor, then the reusability of the module is te be questioned.
It loses its point as a generic component, reusable through the codebase.
Or it is stateless.
Or its state is boundable by the actor.

To answer the second question.
For a module to be composed of actors, means that the messages the actors receive contains somehow information about the context they are executed.
That is, at least, the actors to get the result back.

So, in some extents, it is possible to establish an equivalence between modules and actors. However, the transition is too tedious to be done manually.
That is why most web applications neglect the module approach to adopt the actor approach, when true scalability is needed.
At the lost of the development ease.


% Functional programming isolates the scope of effects for the program to be 
But they all provide some ways to apply the separation of concerns principle : modules.
Think of a module as an object in OOP, or a monad(?) in FP.

It assure that the behavior of a module is completly contained in this module, and does not depends on external parts.
Splitting a large program into many modules allow developers to safely modify a module only by understanding itself, and its interface.
It is the divide and conquer strategy, applied to computer science.
% Separation of concerns. TODO read these :
% - http://en.wikipedia.org/wiki/Separation_of_concerns
% - http://deviq.com/separation-of-concerns/
% - http://stackoverflow.com/questions/98734/what-is-separation-of-concerns
% - http://c2.com/cgi/wiki?SeparationOfConcerns

The separation of concerns principle incites to design simple, generic, reusable modules. 
Some modules can provide more complex behavior, by relying on, and composing with other modules.
The separation of concern incite to develop modules to be generic.
It must be independent from where, and how it is used, to be able to be reused.
De facto, a module is meant to be disseminated through the code base of the program.
Implying that if the module rely on some state, this state must be available in a global memory, and that there is no concurrent access.

This principle allows to quickly develop, and maintain an application.
For a new web application to meet the requirements of its user community, it is crucial to be able to quickly modify its codebase.
\comment{I usually starts from this argument. But here I barely use it. TOOD integrate better this argument.}
% Moreover, it is possible to increase the development team, as the code base is divided into independant parts communicating via well-defined interfaces,
And that is why the development of most, if not all, web applications starts using language allowing with modularity.


\subsection{Performance Scalability}

% \comment{TODO I explain exactly what I mean by Development scalability (I should change the term, it is misleading and not explicit enough), and Performance scalability.}

% How to measure refactoring ease ?

Yet, because of the global memory used to centralize module state, while disseminating the module methods, it is difficult for this first approach to scale.
Indeed, scalability is known to come from parallelism, which is incompatible with a global, shared memory space.
\comment{TODO explain these shortcuts}
\comment{TODO explain the invariance and parallelism. The developer provides insight about parallelization by manipulating the points where invariance of the state is assured. Isolation, locks, or yields}.

At some point, the development team discard this first approach, for a distributed execution model.
Such model distribute the execution onto different computers communicating by messages.
\comment{To simplify the argument, I called these isolated computers, actors. TODO change that name.}
% To maximize the organization possibilities network of actors, it is important that an actor can send a message to any other actor.
The essence of an actor is to have only one execution thread, so as to isolate its state, and have exclusive access on it.
This exclusivity assure the invariance, without relying on synchronization mechanisms.
And if its state is isolated, there is no need to reduce the scope of this actor to reach other actors.
\comment{TODO this argument is not strong enough}

Actors are not composable the way modules are.
The different functions of a module are used in the call / return fashion while actors are used in the fire-and-forget fashion.
An actor sends its result to another actor, than the one which sent the initial message.
It is not possible to compose an actor, like it is possible for a module.
That is, it is not possible to use an actor in different contexts.


The best way to assure parallelism is through isolation.
Yet, the way that developers seems to find most appealing to assure concurrency is through cooperative scheduling aka event-loops.
We observe that there is no large community around languages/frameworks providing isolation.
But there is large communities around languages/frameworks with event-loops.

\subsection{A universal language : the holy Graal}

% \comment{TODO assure transition, explain more about this argument}
% Therefore, it is important to decouple the physical resources used during the execution, and the modularity used to develop the application.

Is it still possible to combine the advantages of modules, with the advantages of actors ?
Is it possible for modules to extend beyond the boundaries of actors, using message-passing, instead of global memory for coordination ?
And is it possible for a module to be composed of actors ?

To answer the first question.
If a module is limited inside an actor, then the reusability of the module is te be questioned.
It loses its point as a generic component, reusable through the codebase.
Or it is stateless.
Or its state is boundable by the actor.

To answer the second question.
For a module to be composed of actors, means that the messages the actors receive contains somehow information about the context they are executed.
That is, at least, the actors to get the result back.

So, in some extents, it is possible to establish an equivalence between modules and actors. However, the transition is too tedious to be done manually.
That is why most web applications neglect the module approach to adopt the actor approach, when true scalability is needed.
At the lost of the development ease.


% Functional programming isolates the scope of effects for the program to be more readable -> it is roughly separation of concern.
% Parallelism needs isolation to avoid race conditions and state corruption.

% You want to isolate a module to be able to understand it, only by looking at its code, and not the whole codebase. But you want it to be reused in many places in the code.

% You want to isolate an actor so that it can have exclusive access to its state.
% But you want it to be able to reach any other actor.





\comment{TODO why ?}


The transposition from the module organization, to the actor organization is a tedious process, and should be handled by a compiler.
Therefore, to have both performance through parallelism and still attract a large developer community, we need to find an equivalence between the module organization, and the performance point of view on parallelism.

\comment{TODO now talk about the limitations of this transition. you mention earlier that actors need to receive information about their context, and that modules needs to be stateless, or that their states needs to be bounded by the actor.}

So the hypothesis is : by providing a tool to transform the invariance of cooperative scheduling into isolation and message-passing, it should be possible to provide a developer-friendly scalable paradigm.
\comment{I don't know if hypothesis is the right term for this assumption}

This transformation is done by isolating the memory use by each atomic execution of the event-loop (the callbacks).
But this isolation is not possible for every kind of application.
Applications could be classified in the level of coordination necessary in their design. (See below for a classification from Gunther's Universal Scalability Law)
At a very end of the spectrum, there is static content servers, where there is no coordination, everything is parallel.
At the very other end of this spectrum, there are consistent databases, where the coordination require the application to be highly sequential.

Web applications that are designed in a certain way (flow-based web applications -> no retropropagation) are in the middle of this spectrum.
We advance as the thesis that it is possible for these types of web applications to isolate the memory for each atomic execution of the event-loop (the callbacks).



The different kind of applications, from Gunther's Universal Scalability Law (USL) :
Application classes for the USL model.

\begin{tabular}{c|l} \hline

\multirow{4}{*}{A} & \textbf{Ideal concurrency} ($\alpha, \beta = 0$)      \\
                   & Single-threaded tasks                                 \\
                   & Parallel text search                                  \\
                   & Read-only queries                                     \\ \hline
\multirow{4}{*}{B} & \textbf{Contention-limited} ($\alpha > 0, \beta = 0$) \\
                   & Tasks requiring locking or sequencing                 \\
                   & Message-passing protocols                             \\
                   & Polling protocols (e.g., hypervisors)                 \\ \hline
\multirow{3}{*}{C} & \textbf{Coherency-limited} ($\alpha = 0, \beta > 0$)  \\
                   & SMP cache pinging                                     \\
                   & Incoherent application state between cluster nodes    \\ \hline
\multirow{4}{*}{D} & \textbf{Worst case} ($\alpha, \beta > 0$)             \\
                   & Tasks acting on shared-writable data                  \\
                   & Online reservation systems                            \\
                   & Updating database records                             \\ \hline
\end{tabular}
\\~\\












\section{Proposal and Hypothesis}

\subsection{LiquidIT}

A general definition of Liquid IT.
And more specifically the focus on dev and perf scalability.
Liquid IT should try to bring a solution to this compromise leveraging the particular position of Javascript and its event-loop.


\subsection{Parallelization and distribution of web applications}
% \subsection{Pipeline parallelism for event-loop}


\subsection{\comment{Hypothesis and Thesis}}




%-----------------------------------------------------------------------------%
                                    \endinput
%-----------------------------------------------------------------------------%


Some links I NEED to put :
--------------------------

https://glyph.twistedmatrix.com/2014/02/unyielding.html
http://calculist.org/blog/2011/12/14/why-coroutines-wont-work-on-the-web/


Some chunks I might find useful later :
---------------------------------------

\cit{No matter how great the talent or efforts, some things just take time. You can't produce a baby in one month by getting nine women pregnant.}
{Warren Buffett}

A good example of declarative sentence in everyday world : in case of fire, 
the elevators don't work -> you understand that you need to take the stairs.

The purpose of explicit synchronization is to manage the timing of side-effects in the presence of parallelism. 

A function is side-effect free if it is referentially transparent.




Why is that cooking recipe are inehrently and easily parallel, while it is a lot more difficult to write parallel programs ?

The intuitive understandings of the scope of side-effects.
In a recipe, it is easy to understand what each steps do, and how it might interfere with others, or which are required by others.
With the naivete of computers, every interaction needs to be explicitely defined to avoid conflict.
And with the size of programs, it is important to keep these interactions to a minimum.

While in a computer program, it is a lot more difficult.
It boils down to have boundaries in your system, and coordination to articulate the parts.

The two extremes are functional programming, message passing, actor model, multi-process, with statelessness, side-effects free, referential transparency ...
\comment{TODO there is HUGE differences between all these concepts. The common point is isolation of memory in space (rather than time with the following solution), but in terms of composition, functional programming and every other, are completly different. FP allows composition (the same point handle call and returns, a single point of connection), which is not true to message passing and so on ...}
And Shared memory multi-threading, with locks, transaction memory ...
Which basically isolate memory in time.





The original explanation :
--------------------------

Languages with parallel execution features are not mainstream, because it is difficult to provide a good way for the developer to coordinate between the different parallel executions.
The two main current designs for this coordination are synchronization mechanims for threads, or isolation for processes.
Both are pretty difficult to manage.
It is known that synchronization is difficult. \comment{TODO Develop this further, with arguments}
And as we see from many parallel languages or frameworks, isolation-based coordination never really took off. Probably because it is too difficult for most programmers to efficiently manage both the isolation, and the features organization.
\comment{TODO a better explanation is needed here (inspiration from the abstract), and some solid arguments}

These two methods assure to the developer the invariance in the memory.
If we step back from parallelism, into all concurrency, we have three methods to assure this invariance :
\begin{itemize}
\item Synchronization mechanisms are used by threads to assure that no other threads is using a common memory region : it assure the invariance of this memory region during the execution. But it is known to be difficult to develop scalable applications with such mechanisms.
\comment{TODO develop this with arguments, maybe merge with above}
\item Isolation is another way to assure the invariance : each process is sure to have exclusive access to its memory, and therefore, it assure the invariance.
It is used by parallel frameworks, but it require the developer to think both at feature modularization and isolation.
We suppose that the two are not easily conciliable, and that is why we observe that isolation-based languages and frameworks never really took off.
\comment{TODO arguments}
\item Exclusive atomic execution is a third way to assure invariance. It is used by the Javascript event-loop. It assure that a) each execution is atomic until it yield b) the developer is aware of this yielding, and acknowledge the invariance between the yields.
But as the execution is localized to keep a global memory, it is not parallel and therefore, not scalable.
\end{itemize}

There is two different levels here.
The developer point of view seems inconsiliable with the performance point of view.

From the developer end, the best way for developer to easily acknowledge this invariance in a concurrent execution seems to be through sequential atomic and exclusive executions : Cooperative scheduling, like used by the event loop.
But this cooperative scheduling must remain managed by the developer (at least for the moment), therefore, it is important to keep keyword like yield, and so, and not rush into the green thread paradigm \comment{see the article unyielding on deciphering glyph's blog}.
The memory is global (to assure coordination), but accessed in turns.

From the performance end, the best way to assure scalability is through a parallelism based on isolation, and message-passing.
The memory is splitted in isolated and exclusive portions, with messages to assure the coordination.
\comment{TODO argue why it is the best way}

Therefore, to have both performance through parallelism and still attract a large developer community, we need to find an equivalence between the developer point of view on the invariance, and the performance point of view on parallelism.

So the hypothesis is : by providing a tool to transform the invariance of cooperative scheduling into isolation and message-passing, it should be possible to provide a developer-friendly scalable paradigm.
\comment{I don't know if hypothesis is the right term for this assumption}

This transformation is done by isolating the memory use by each atomic execution of the event-loop (the callbacks).
But this isolation is not possible for every kind of application.
Applications could be classified in the level of coordination necessary in their design. (See below for a classification from Gunther's Universal Scalability Law)
At a very end of the spectrum, there is static content servers, where there is no coordination, everything is parallel.
At the very other end of this spectrum, there are consistent databases, where the coordination require the application to be highly sequential.

Web applications that are designed in a certain way (flow-based web applications -> no retropropagation) are in the middle of this spectrum.
We advance as the thesis that it is possible for these types of web applications to isolate the memory for each atomic execution of the event-loop (the callbacks).



The different kind of applciations, from Gunther's Universal Scalability Law (USL) :
Application classes for the USL model.

\begin{tabular}{c|l} \hline

\multirow{4}{*}{A} & \textbf{Ideal concurrency} ($\alpha, \beta = 0$)      \\
                   & Single-threaded tasks                                 \\
                   & Parallel text search                                  \\
                   & Read-only queries                                     \\ \hline
\multirow{4}{*}{B} & \textbf{Contention-limited} ($\alpha > 0, \beta = 0$) \\
                   & Tasks requiring locking or sequencing                 \\
                   & Message-passing protocols                             \\
                   & Polling protocols (e.g., hypervisors)                 \\ \hline
\multirow{3}{*}{C} & \textbf{Coherency-limited} ($\alpha = 0, \beta > 0$)  \\
                   & SMP cache pinging                                     \\
                   & Incoherent application state between cluster nodes    \\ \hline
\multirow{4}{*}{D} & \textbf{Worst case} ($\alpha, \beta > 0$)             \\
                   & Tasks acting on shared-writable data                  \\
                   & Online reservation systems                            \\
                   & Updating database records                             \\ \hline
\end{tabular}
\\~\\
