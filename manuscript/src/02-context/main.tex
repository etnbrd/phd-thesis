\chapter{Context and objectives}

\minitoc

\input{02-context/Web-as-a-platform}

\section{The pivot \comment{Problem}}

% But many large company replaced the initial languages of the web with scalable solutions.
% Twitter : Ruby -> Storm
% Facebook : PHP -> HHVM / Flux ...
% Google : MapReduce, Kubernetes, Borg ...

\subsection{Separation of concerns}


% I see a trend here.
% http://pchiusano.blogspot.fr/2010/01/actors-are-not-good-concurrency-model.html

The languages presented in the last section all have large developing community. Some are functional, others are object-oriented.
But they all provide some ways to apply the separation of concerns principle : modules.
Think of a module as an object in OOP, or a monad(?) in FP.

It assure that the behavior of a module is completly contained in this module, and does not depends on external parts.
Splitting a large program into many modules allow developers to safely modify a module only by understanding itself, and its interface.
It is the divide and conquer strategy, applied to computer science.
% Separation of concerns. TODO read these :
% - http://en.wikipedia.org/wiki/Separation_of_concerns
% - http://deviq.com/separation-of-concerns/
% - http://stackoverflow.com/questions/98734/what-is-separation-of-concerns
% - http://c2.com/cgi/wiki?SeparationOfConcerns

The separation of concerns principle incites to design simple, generic, reusable modules. 
Some modules can provide more complex behavior, by relying on, and composing with other modules.
The separation of concern impose a module to be generic.
It must be independent from where, and how it is used, to be able to be reused.
De facto, a module is meant to be disseminated through the code base of the program.
Implying that if the module holds state, this state is available in a global memory, and that there is no concurent access.

This principle allows to quickly develop, and maintain an application.
For a new web application to meet the requirements of its user community, it is crucial to be able to quickly modify its codebase.
% Moreover, it is possible to increase the development team, as the code base is divided into independant parts communicating via well-defined interfaces,
And that is why the development of most, if not all, web applications starts using language allowing with modularity.


\subsection{Performance Scalability}

% \comment{TODO I explain exactly what I mean by Development scalability (I should change the term, it is misleading and not explicit enough), and Performance scalability.}

% How to measure refactoring ease ?

Yet, because of the global memory used to centralize module state, while disseminating the module methods, it is difficult for this first approach to scale.
Indeed, scalability is known to come from parallelism, which is incompatible global, shared memory space.
\comment{TODO explain these shortcuts}
\comment{TODO I completly skip the point about invariance. The developer provides insight about parallelization by manipulating the points where invariance of the state is assured. Isolation, locks, or yields}.

At some point, the development team discard this first approach, for a distributed execution model.
Such model distribute the execution onto different computers communicating by messages.
\comment{To simplify the argument, I called these isolated computers, actors. TODO change that name.}
% To maximize the organization possibilities network of actors, it is important that an actor can send a message to any other actor.
The essence of an actor is to have only one execution thread, to be able to isolate its state.
And if its state is isolated, there is no need to reduce the scope of this actor to reach other actors.
\comment{TODO this argument is not strong enough}

Actors are not composable the way modules are.
The different functions of a module are used in the call / return fashionn while actors are used in the fire-and-forget fashion.
An actor sends its result to another actor, than the one which sent the initial message.
It is not possible to compose an actor, like it is possible for a module.
That is, it is not possible to use an actor in different contexts.


\subsection{The holy graal}

% \comment{TODO assure transition, explain more about this argument}
% Therefore, it is important to decouple the physical resources used during the execution, and the modularity used to develop the application.

Is it still possible to combine the advantages of modules, with the advantages of actors ?
Is it possible for an actor to be the boundary for some modules ?
Or is it possible for a module to be composed of actors ?

To answer the first question.
If a module is limited inside an actor, then the reusability of the module is te be questioned.
It loses its point as a generic component, reusable through the codebase.
Or it is stateless.
Or its state is boundable by the actor.

To answer the second question.
For a module to be composed of actors, means that the messages the actors receive contains somehow information about the context they are executed.
That is, at least, the actors to get the result back.

So, in some extents, it is possible to establish an equivalence between modules and actors. However, the transition is too tedious to be done manually.
That is why most web applications neglect the module approach to adopt the actor approach, when true scalability is needed.
At the lost of the development ease.


% Functional programming isolates the scope of effects for the program to be more readable -> it is roughly separation of concern.
% Parallelism needs isolation to avoid race conditions and state corruption.

% You want to isolate a module to be able to understand it, only by looking at its code, and not the whole codebase. But you want it to be reused in many places in the code.

% You want to isolate an actor so that it can have exclusive access to its state.
% But you want it to be able to reach any other actor.





\comment{TODO why ?}


The transposition from the module organization, to the actor organization is a tedious process, and should be handled by a compiler.
Therefore, to have both performance through parallelism and still attract a large developer community, we need to find an equivalence between the module organization, and the performance point of view on parallelism.

\comment{TODO now talk about the limitations of this transition. you mention earlier that actors need to receive information about their context, and that modules needs to be stateless, or that their states needs to be bounded by the actor.}

So the hypothesis is : by providing a tool to transform the invariance of cooperative scheduling into isolation and message-passing, it should be possible to provide a developer-friendly scalable paradigm.
\comment{I don't know if hypothesis is the right term for this assumption}

This transformation is done by isolating the memory use by each atomic execution of the event-loop (the callbacks).
But this isolation is not possible for every kind of application.
Applications could be classified in the level of coordination necessary in their design. (See below for a classification from Gunther's Universal Scalability Law)
At a very end of the spectrum, there is static content servers, where there is no coordination, everything is parallel.
At the very other end of this spectrum, there are consistent databases, where the coordination require the application to be highly sequential.

Web applications that are designed in a certain way (flow-based web applications -> no retropropagation) are in the middle of this spectrum.
We advance as the thesis that it is possible for these types of web applications to isolate the memory for each atomic execution of the event-loop (the callbacks).



The different kind of applciations, from Gunther's Universal Scalability Law (USL) :
Application classes for the USL model.

\begin{tabular}{c|l} \hline

\multirow{4}{*}{A} & \textbf{Ideal concurrency} ($\alpha, \beta = 0$)      \\
                   & Single-threaded tasks                                 \\
                   & Parallel text search                                  \\
                   & Read-only queries                                     \\ \hline
\multirow{4}{*}{B} & \textbf{Contention-limited} ($\alpha > 0, \beta = 0$) \\
                   & Tasks requiring locking or sequencing                 \\
                   & Message-passing protocols                             \\
                   & Polling protocols (e.g., hypervisors)                 \\ \hline
\multirow{3}{*}{C} & \textbf{Coherency-limited} ($\alpha = 0, \beta > 0$)  \\
                   & SMP cache pinging                                     \\
                   & Incoherent application state between cluster nodes    \\ \hline
\multirow{4}{*}{D} & \textbf{Worst case} ($\alpha, \beta > 0$)             \\
                   & Tasks acting on shared-writable data                  \\
                   & Online reservation systems                            \\
                   & Updating database records                             \\ \hline
\end{tabular}
\\~\\












\section{Proposal and Hypothesis}

\subsection{LiquidIT}

A general definition of Liquid IT.
And more specifically the focus on dev and perf scalability.
Liquid IT should try to bring a solution to this compromise leveraging the particular position of Javascript and its event-loop.


\subsection{Parallelization and distribution of web applications}
% \subsection{Pipeline parallelism for event-loop}


\subsection{\comment{Hypothesis and Thesis}}




%-----------------------------------------------------------------------------%
                                    \endinput
%-----------------------------------------------------------------------------%



Some chunks I might find useful later :
---------------------------------------

\cit{No matter how great the talent or efforts, some things just take time. You can't produce a baby in one month by getting nine women pregnant.}
{Warren Buffett}

A good example of declarative sentence in everyday world : in case of fire, 
the elevators don't work -> you understand that you need to take the stairs.

The purpose of explicit synchronization is to manage the timing of side-effects in the presence of parallelism. 

A function is side-effect free if it is referentially transparent.




Why is that cooking recipe are inehrently and easily parallel, while it is a lot more difficult to write parallel programs ?

The intuitive understandings of the scope of side-effects.
In a recipe, it is easy to understand what each steps do, and how it might interfere with others, or which are required by others.
With the naivete of computers, every interaction needs to be explicitely defined to avoid conflict.
And with the size of programs, it is important to keep these interactions to a minimum.

While in a computer program, it is a lot more difficult.
It boils down to have boundaries in your system, and coordination to articulate the parts.

The two extremes are functional programming, message passing, actor model, multi-process, with statelessness, side-effects free, referential transparency ...
\comment{TODO there is HUGE differences between all these concepts. The common point is isolation of memory in space (rather than time with the following solution), but in terms of composition, functional programming and every other, are completly different. FP allows composition (the same point handle call and returns, a single point of connection), which is not true to message passing and so on ...}
And Shared memory multi-threading, with locks, transaction memory ...
Which basically isolate memory in time.





The original explanation :
--------------------------

Languages with parallel execution features are not mainstream, because it is difficult to provide a good way for the developer to coordinate between the different parallel executions.
The two main current designs for this coordination are synchronization mechanims for threads, or isolation for processes.
Both are pretty difficult to manage.
It is known that synchronization is difficult. \comment{TODO Develop this further, with arguments}
And as we see from many parallel languages or frameworks, isolation-based coordination never really took off. Probably because it is too difficult for most programmers to efficiently manage both the isolation, and the features organization.
\comment{TODO a better explanation is needed here (inspiration from the abstract), and some solid arguments}

These two methods assure to the developer the invariance in the memory.
If we step back from parallelism, into all concurrency, we have three methods to assure this invariance :
\begin{itemize}
\item Synchronization mechanisms are used by threads to assure that no other threads is using a common memory region : it assure the invariance of this memory region during the execution. But it is known to be difficult to develop scalable applications with such mechanisms.
\comment{TODO develop this with arguments, maybe merge with above}
\item Isolation is another way to assure the invariance : each process is sure to have exclusive access to its memory, and therefore, it assure the invariance.
It is used by parallel frameworks, but it require the developer to think both at feature modularization and isolation.
We suppose that the two are not easily conciliable, and that is why we observe that isolation-based languages and frameworks never really took off.
\comment{TODO arguments}
\item Exclusive atomic execution is a third way to assure invariance. It is used by the Javascript event-loop. It assure that a) each execution is atomic until it yield b) the developer is aware of this yielding, and acknowledge the invariance between the yields.
But as the execution is localized to keep a global memory, it is not parallel and therefore, not scalable.
\end{itemize}

There is two different levels here.
The developer point of view seems inconsiliable with the performance point of view.

From the developer end, the best way for developer to easily acknowledge this invariance in a concurrent execution seems to be through sequential atomic and exclusive executions : Cooperative scheduling, like used by the event loop.
But this cooperative scheduling must remain managed by the developer (at least for the moment), therefore, it is important to keep keyword like yield, and so, and not rush into the green thread paradigm \comment{see the article unyielding on deciphering glyph's blog}.
The memory is global (to assure coordination), but accessed in turns.

From the performance end, the best way to assure scalability is through a parallelism based on isolation, and message-passing.
The memory is splitted in isolated and exclusive portions, with messages to assure the coordination.
\comment{TODO argue why it is the best way}

Therefore, to have both performance through parallelism and still attract a large developer community, we need to find an equivalence between the developer point of view on the invariance, and the performance point of view on parallelism.

So the hypothesis is : by providing a tool to transform the invariance of cooperative scheduling into isolation and message-passing, it should be possible to provide a developer-friendly scalable paradigm.
\comment{I don't know if hypothesis is the right term for this assumption}

This transformation is done by isolating the memory use by each atomic execution of the event-loop (the callbacks).
But this isolation is not possible for every kind of application.
Applications could be classified in the level of coordination necessary in their design. (See below for a classification from Gunther's Universal Scalability Law)
At a very end of the spectrum, there is static content servers, where there is no coordination, everything is parallel.
At the very other end of this spectrum, there are consistent databases, where the coordination require the application to be highly sequential.

Web applications that are designed in a certain way (flow-based web applications -> no retropropagation) are in the middle of this spectrum.
We advance as the thesis that it is possible for these types of web applications to isolate the memory for each atomic execution of the event-loop (the callbacks).



The different kind of applciations, from Gunther's Universal Scalability Law (USL) :
Application classes for the USL model.

\begin{tabular}{c|l} \hline

\multirow{4}{*}{A} & \textbf{Ideal concurrency} ($\alpha, \beta = 0$)      \\
                   & Single-threaded tasks                                 \\
                   & Parallel text search                                  \\
                   & Read-only queries                                     \\ \hline
\multirow{4}{*}{B} & \textbf{Contention-limited} ($\alpha > 0, \beta = 0$) \\
                   & Tasks requiring locking or sequencing                 \\
                   & Message-passing protocols                             \\
                   & Polling protocols (e.g., hypervisors)                 \\ \hline
\multirow{3}{*}{C} & \textbf{Coherency-limited} ($\alpha = 0, \beta > 0$)  \\
                   & SMP cache pinging                                     \\
                   & Incoherent application state between cluster nodes    \\ \hline
\multirow{4}{*}{D} & \textbf{Worst case} ($\alpha, \beta > 0$)             \\
                   & Tasks acting on shared-writable data                  \\
                   & Online reservation systems                            \\
                   & Updating database records                             \\ \hline
\end{tabular}
\\~\\
