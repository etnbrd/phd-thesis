\section{Introduction}

The growth of web services is partially due to Internet's capacity to allow very quick releases of a minimal viable product (MVP).
In a matter of hours, it is possible to release a prototype and start gathering a user community.
\textit{``Release early, release often''}, and \textit{``Fail fast''} are the punchlines of the web entrepreneurial community.
It is crucial for the prosperity of such project to quickly validate that the proposed solution meets the needs of its users.
Indeed, the lack of market need is the first reason for startup failure\ftnt{https://www.cbinsights.com/blog/startup-failure-post-mortem/}.
Hence the development team quickly concretizes an MVP using a feature-driven approach and iterates on it.

If the service successfully complies with users requirements, its community grows with its popularity.
The service needs to be scalable, thus parallel, to be able to respond to this growth.
However, feature-based development best practices are hardly compatible with this parallelism.
The features are organized in modules which overlap and disturb the organization of a parallel execution.
Eventually this growth requires to discard the initial approach to adopt a more efficient processing model.
Many of the most efficient models decompose applications into execution units, disregarding the initial feature oriented approach.
This decomposition may be spread over a cluster of commodity machines. % \cite{Fox1997}.
MapReduce \cite{Dean2008} and the Staged Event-driven Architecture (SEDA) \cite{Welsh2000} are famous examples of that trend. %, using a pipeline architecture.
Once split, the service parts are connected by an asynchronous messaging system.
Many tools have been developed to express and manage these service parts and their communications.
We can cite Spark \cite{Zaharia2012}, MillWheel \cite{Akidau2013}, Naiad \cite{McSherry} and Storm \cite{Toshniwal2014}, and many others.
However, these tools are in disruption from the initial approach.
It requires the development team either to be trained or to hire experts, and more importantly, to start over the initial code base.
This shift causes the development team to spend development resources in background without adding visible value for the users.
It is a risk for the evolution of the project as the second and third reasons for startup failures are running out of cash, and missing the right competences$^2$.
% \ftnt{https://www.cbinsights.com/blog/startup-failure-post-mortem/}

The risks described above come from a disruption between the two levels of application expression, the feature level and the execution level.
To lift these risks, we propose a tool to identify an alignment between the two levels, so as to allow a continuous transition from one to the other and back.
% This compiler transforms the initial code base into a high-level language.
% in the application allowing parallelism, hence scalability.
We focus on web applications driven by users requests, developed in Javascript using the \textit{Node.js} execution environment.

Javascript is increasingly used to develop web applications.
It is the most used language on Github\ftnt{http://githut.info/} and StackOverflow\ftnt{http://stackoverflow.com/tags}.
We think that it is possible to analyze this type of application as a stream of requests, passing through a pipeline of stages.
Indeed, the event-loop used in \textit{Node.js} is very similar to a pipeline architecture.
We propose a compiler to transform a Javascript application into a network of independent parts communicating by message streams and executed in parallel.
We named these parts \textit{fluxions}, by contraction between a flux and a function.
We are interested in the problems arising from the isolation of the global memory into these fluxions.
%This tool and its runtime aim not to modify the existing code, but rely on a high-level language expression over the initial code base.
The contribution of this paper is the resolution of these problems, allowing the compilation.
We present an early version of this tool as a proof of concept for this compilation approach.
We start by describing in section \ref{section:model} the execution environment targeted by this compiler.
Then, we present the compiler in section \ref{section:compiler}, and its evaluation in section \ref{section:evaluation}.
We compare our work with related works in section \ref{section:related}.
And finally, we conclude this paper.